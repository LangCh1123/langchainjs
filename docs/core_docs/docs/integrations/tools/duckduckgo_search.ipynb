{
 "cells": [
  {
   "cell_type": "raw",
   "id": "10238e62-3465-4973-9279-606cbb7ccf16",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "sidebar_label: DuckDuckGoSearch\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f91f20",
   "metadata": {},
   "source": [
    "# DuckDuckGoSearch\n",
    "\n",
    "This notebook provides a quick overview for getting started with [DuckDuckGoSearch](/docs/integrations/tools/). For detailed documentation of all DuckDuckGoSearch features and configurations head to the [API reference](https://api.js.langchain.com/classes/langchain_community_tools_duckduckgo_search.DuckDuckGoSearch.html).\n",
    "\n",
    "DuckDuckGoSearch offers a privacy-focused search API designed for LLM Agents. It provides seamless integration with a wide range of data sources, prioritizing user privacy and relevant search results.\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Integration details\n",
    "\n",
    "| Class | Package | Serializable | [PY support](https://python.langchain.com/docs/integrations/tools/ddg/) |  Package latest |\n",
    "| :--- | :--- | :---: | :---: | :---: |\n",
    "| [DuckDuckGoSearch](https://api.js.langchain.com/classes/langchain_community_tools_duckduckgo_search.DuckDuckGoSearch.html) | [@langchain/community](https://api.js.langchain.com/modules/langchain_community_tools_duckduckgo_search.html) | beta | âœ… |  ![NPM - Version](https://img.shields.io/npm/v/@langchain/community?style=flat-square&label=%20&) |\n",
    "\n",
    "### Tool features\n",
    "\n",
    "- TODO: Add feature table if it makes sense\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "The integration lives in the `@langchain/community` package, along with the `duck-duck-scrape` dependency:\n",
    "\n",
    "```{=mdx}\n",
    "import IntegrationInstallTooltip from \"@mdx_components/integration_install_tooltip.mdx\";\n",
    "import Npm2Yarn from \"@theme/Npm2Yarn\";\n",
    "\n",
    "<IntegrationInstallTooltip></IntegrationInstallTooltip>\n",
    "\n",
    "<Npm2Yarn>\n",
    "  @langchain/community duck-duck-scrape\n",
    "</Npm2Yarn>\n",
    "```\n",
    "\n",
    "### Credentials\n",
    "\n",
    "It's also helpful (but not needed) to set up [LangSmith](https://smith.langchain.com/) for best-in-class observability:\n",
    "\n",
    "```typescript\n",
    "process.env.LANGCHAIN_TRACING_V2=\"true\"\n",
    "process.env.LANGCHAIN_API_KEY=\"your-api-key\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c97218f-f366-479d-8bf7-fe9f2f6df73f",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Here we show how to insatiate an instance of the `DuckDuckGoSearch` tool, with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b3ddfe9-ca79-494c-a7ab-1f56d9407a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { DuckDuckGoSearch } from \"@langchain/community/tools/duckduckgo_search\"\n",
    "\n",
    "const tool = new DuckDuckGoSearch({ maxResults: 1 })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74147a1a",
   "metadata": {},
   "source": [
    "## Invocation\n",
    "\n",
    "### [Invoke directly with args](/docs/concepts/#invoke-with-just-the-arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65310a8b-eb0c-4d9e-a618-4f4abe2414fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"title\":\"Anthropic forecasts more than $850 mln in annualized revenue rate by ...\",\"link\":\"https://www.reuters.com/technology/anthropic-forecasts-more-than-850-mln-annualized-revenue-rate-by-2024-end-report-2023-12-26/\",\"snippet\":\"Dec 26 (Reuters) - Artificial intelligence startup <b>Anthropic</b> has projected it will generate more than $850 million in annualized <b>revenue</b> by the end of <b>2024</b>, the Information reported on Tuesday ...\"}]\n"
     ]
    }
   ],
   "source": [
    "await tool.invoke(\"What is Anthropic's estimated revenue for 2024?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e73897",
   "metadata": {},
   "source": [
    "### [Invoke with ToolCall](/docs/concepts/#invoke-with-toolcall)\n",
    "\n",
    "We can also invoke the tool with a model-generated `ToolCall`, in which case a `ToolMessage` will be returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90e33a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolMessage {\n",
      "  \"content\": \"[{\\\"title\\\":\\\"Anthropic forecasts more than $850 mln in annualized revenue rate by ...\\\",\\\"link\\\":\\\"https://www.reuters.com/technology/anthropic-forecasts-more-than-850-mln-annualized-revenue-rate-by-2024-end-report-2023-12-26/\\\",\\\"snippet\\\":\\\"Dec 26 (Reuters) - Artificial intelligence startup <b>Anthropic</b> has projected it will generate more than $850 million in annualized <b>revenue</b> by the end of <b>2024</b>, the Information reported on Tuesday ...\\\"}]\",\n",
      "  \"name\": \"duckduckgo-search\",\n",
      "  \"additional_kwargs\": {},\n",
      "  \"response_metadata\": {},\n",
      "  \"tool_call_id\": \"tool_call_id\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// This is usually generated by a model, but we'll create a tool call directly for demo purposes.\n",
    "const modelGeneratedToolCall = {\n",
    "  args: {\n",
    "    input: \"What is Anthropic's estimated revenue for 2024?\"\n",
    "  },\n",
    "  id: \"tool_call_id\",\n",
    "  name: tool.name,\n",
    "  type: \"tool_call\",\n",
    "}\n",
    "await tool.invoke(modelGeneratedToolCall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659f9fbd-6fcf-445f-aa8c-72d8e60154bd",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "We can use our tool in a chain by first binding it to a [tool-calling model](/docs/how_to/tool_calling/) and then calling it:\n",
    "\n",
    "```{=mdx}\n",
    "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
    "\n",
    "<ChatModelTabs customVarName=\"llm\" />\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af3123ad-7a02-40e5-b58e-7d56e23e5830",
   "metadata": {},
   "outputs": [],
   "source": [
    "// @lc-docs-hide-cell\n",
    "\n",
    "import { ChatOpenAI } from \"@langchain/openai\"\n",
    "\n",
    "const llm = new ChatOpenAI({\n",
    "  model: \"gpt-4o-mini\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdbf35b5-3aaf-4947-9ec6-48c21533fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\"\n",
    "import { RunnableConfig } from \"@langchain/core/runnables\"\n",
    "import { AIMessage } from \"@langchain/core/messages\"\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromMessages(\n",
    "  [\n",
    "    [\"system\", \"You are a helpful assistant.\"],\n",
    "    [\"human\", \"{user_input}\"],\n",
    "    [\"placeholder\", \"{messages}\"],\n",
    "  ]\n",
    ")\n",
    "\n",
    "// specifying tool_choice will force the model to call this tool.\n",
    "const llmWithTools = llm.bindTools([tool], {\n",
    "  tool_choice: tool.name\n",
    "})\n",
    "\n",
    "const llmChain = prompt.pipe(llmWithTools);\n",
    "\n",
    "const toolChain = async (userInput: string, config?: RunnableConfig): Promise<AIMessage> => {\n",
    "  const input_ = { user_input: userInput };\n",
    "  const aiMsg = await llmChain.invoke(input_, config);\n",
    "  const toolMsgs = await tool.batch(aiMsg.tool_calls, config);\n",
    "  return llmChain.invoke({ ...input_, messages: [aiMsg, ...toolMsgs] }, config);\n",
    "};\n",
    "\n",
    "const toolChainResult = await toolChain(\"What is Anthropic's estimated revenue for 2024?\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28448fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"tool_calls\": [\n",
      "    {\n",
      "      \"name\": \"duckduckgo-search\",\n",
      "      \"args\": {\n",
      "        \"input\": \"Anthropic revenue 2024 forecast\"\n",
      "      },\n",
      "      \"type\": \"tool_call\",\n",
      "      \"id\": \"call_E22L1T1bI6xPrMtL8wrKW5C5\"\n",
      "    }\n",
      "  ],\n",
      "  \"content\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const { tool_calls, content } = toolChainResult;\n",
    "\n",
    "console.log(\"AIMessage\", JSON.stringify({\n",
    "  tool_calls,\n",
    "  content\n",
    "}, null, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ceafa7",
   "metadata": {},
   "source": [
    "## With an agent\n",
    "\n",
    "We can also pass the `DuckDuckGoSearch` tool to an agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77a05a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  input: \"What is Anthropic's estimated revenue for 2024?\",\n",
      "  output: 'Anthropic has projected that it will generate more than $850 million in annualized revenue by the end of 2024.'\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { DuckDuckGoSearch } from \"@langchain/community/tools/duckduckgo_search\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import type { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "import { pull } from \"langchain/hub\";\n",
    "import { AgentExecutor, createOpenAIFunctionsAgent } from \"langchain/agents\";\n",
    "\n",
    "// Define the tools the agent will have access to.\n",
    "const toolsForAgent = [new DuckDuckGoSearch({ maxResults: 1 })];\n",
    "\n",
    "// Get the prompt to use - you can modify this!\n",
    "// If you want to see the prompt in full, you can at:\n",
    "// https://smith.langchain.com/hub/hwchase17/openai-functions-agent\n",
    "const promptForAgent = await pull<ChatPromptTemplate>(\n",
    "  \"hwchase17/openai-functions-agent\"\n",
    ");\n",
    "const llmForAgent = new ChatOpenAI({\n",
    "  model: \"gpt-4-turbo-preview\",\n",
    "  temperature: 0,\n",
    "});\n",
    "const agent = await createOpenAIFunctionsAgent({\n",
    "  llm: llmForAgent,\n",
    "  tools: toolsForAgent,\n",
    "  prompt: promptForAgent,\n",
    "});\n",
    "const agentExecutor = new AgentExecutor({\n",
    "  agent,\n",
    "  tools: toolsForAgent,\n",
    "});\n",
    "const agentResult = await agentExecutor.invoke({\n",
    "  input: \"What is Anthropic's estimated revenue for 2024?\",\n",
    "});\n",
    "\n",
    "console.log(agentResult);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac8146c",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all DuckDuckGoSearch features and configurations head to the [API reference](https://api.js.langchain.com/classes/langchain_community_tools_duckduckgo_search.DuckDuckGoSearch.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
