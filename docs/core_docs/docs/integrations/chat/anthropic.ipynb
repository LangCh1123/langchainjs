{
 "cells": [
  {
   "cell_type": "raw",
   "id": "afaf8039",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "sidebar_label: Anthropic\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f1e0d",
   "metadata": {},
   "source": [
    "# ChatAnthropic\n",
    "\n",
    "[Anthropic](https://www.anthropic.com/) is an AI safety and research company. They are the creator of Claude.\n",
    "\n",
    "This will help you getting started with Anthropic [chat models](/docs/concepts/#chat-models). For detailed documentation of all `ChatAnthropic` features and configurations head to the [API reference](https://api.js.langchain.com/classes/langchain_anthropic.ChatAnthropic.html).\n",
    "\n",
    "## Overview\n",
    "### Integration details\n",
    "\n",
    "| Class | Package | Local | Serializable | [PY support](https://python.langchain.com/docs/integrations/chat/anthropic/) | Package downloads | Package latest |\n",
    "| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\n",
    "| [ChatAnthropic](https://api.js.langchain.com/classes/langchain_anthropic.ChatAnthropic.html) | [@langchain/anthropic](https://api.js.langchain.com/modules/langchain_anthropic.html) | ❌ | ✅ | ✅ | ![NPM - Downloads](https://img.shields.io/npm/dm/@langchain/anthropic?style=flat-square&label=%20&) | ![NPM - Version](https://img.shields.io/npm/v/@langchain/anthropic?style=flat-square&label=%20&) |\n",
    "\n",
    "### Model features\n",
    "| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\n",
    "| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: |\n",
    "| ✅ | ✅ | ❌ | ✅ | ❌ | ❌ | ✅ | ✅ | ❌ | \n",
    "\n",
    "## Setup\n",
    "\n",
    "You'll need to sign up and obtain an [Anthropic API key](https://www.anthropic.com/), and install the `@langchain/anthropic` integration package.\n",
    "\n",
    "### Credentials\n",
    "\n",
    "Head to [Anthropic's website](https://www.anthropic.com/) to sign up to Anthropic and generate an API key. Once you've done this set the `ANTHROPIC_API_KEY` environment variable:\n",
    "\n",
    "```bash\n",
    "export ANTHROPIC_API_KEY=\"your-api-key\"\n",
    "```\n",
    "\n",
    "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n",
    "\n",
    "```bash\n",
    "# export LANGCHAIN_TRACING_V2=\"true\"\n",
    "# export LANGCHAIN_API_KEY=\"your-api-key\"\n",
    "```\n",
    "\n",
    "### Installation\n",
    "\n",
    "The LangChain `ChatAnthropic` integration lives in the `@langchain/anthropic` package:\n",
    "\n",
    "```{=mdx}\n",
    "\n",
    "import IntegrationInstallTooltip from \"@mdx_components/integration_install_tooltip.mdx\";\n",
    "import Npm2Yarn from \"@theme/Npm2Yarn\";\n",
    "\n",
    "<IntegrationInstallTooltip></IntegrationInstallTooltip>\n",
    "\n",
    "<Npm2Yarn>\n",
    "  @langchain/anthropic\n",
    "</Npm2Yarn>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cde65-254d-4219-a441-068766c0d4b5",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Now we can instantiate our model object and generate chat completions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb09c344-1836-4e0c-acf8-11d13ac1dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatAnthropic } from \"@langchain/anthropic\" \n",
    "\n",
    "const llm = new ChatAnthropic({\n",
    "    model: \"claude-3-haiku-20240307\",\n",
    "    temperature: 0,\n",
    "    maxTokens: undefined,\n",
    "    maxRetries: 2,\n",
    "    // other params...\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f3e15",
   "metadata": {},
   "source": [
    "## Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e0dbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"msg_01M9yt3aSqKJKM1RnZF4f44Q\",\n",
      "  \"content\": \"Voici la traduction en français :\\n\\nJ'adore la programmation.\",\n",
      "  \"additional_kwargs\": {\n",
      "    \"id\": \"msg_01M9yt3aSqKJKM1RnZF4f44Q\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 29,\n",
      "      \"output_tokens\": 20\n",
      "    }\n",
      "  },\n",
      "  \"response_metadata\": {\n",
      "    \"id\": \"msg_01M9yt3aSqKJKM1RnZF4f44Q\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 29,\n",
      "      \"output_tokens\": 20\n",
      "    },\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 29,\n",
      "    \"output_tokens\": 20,\n",
      "    \"total_tokens\": 49\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const aiMsg = await llm.invoke([\n",
    "    [\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ],\n",
    "    [\"human\", \"I love programming.\"],\n",
    "])\n",
    "aiMsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d86145b3-bfef-46e8-b227-4dda5c9c2705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici la traduction en français :\n",
      "\n",
      "J'adore la programmation.\n"
     ]
    }
   ],
   "source": [
    "console.log(aiMsg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2bfc0-7e78-4528-a73f-499ac150dca8",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "We can [chain](/docs/how_to/sequence/) our model with a prompt template like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e197d1d7-a070-4c96-9f8a-a0e86d046e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"msg_012gUKUG65teaois31W3bfGF\",\n",
      "  \"content\": \"Ich liebe das Programmieren.\",\n",
      "  \"additional_kwargs\": {\n",
      "    \"id\": \"msg_012gUKUG65teaois31W3bfGF\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 23,\n",
      "      \"output_tokens\": 11\n",
      "    }\n",
      "  },\n",
      "  \"response_metadata\": {\n",
      "    \"id\": \"msg_012gUKUG65teaois31W3bfGF\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 23,\n",
      "      \"output_tokens\": 11\n",
      "    },\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 23,\n",
      "    \"output_tokens\": 11,\n",
      "    \"total_tokens\": 34\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\"\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromMessages(\n",
    "    [\n",
    "        [\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ],\n",
    "        [\"human\", \"{input}\"],\n",
    "    ]\n",
    ")\n",
    "\n",
    "const chain = prompt.pipe(llm);\n",
    "await chain.invoke(\n",
    "    {\n",
    "        input_language: \"English\",\n",
    "        output_language: \"German\",\n",
    "        input: \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ee55bc-ffc8-4cfa-801c-993953a08cfd",
   "metadata": {},
   "source": [
    "## Multimodal inputs\n",
    "\n",
    "Claude-3 models support image multimodal inputs. The passed input must be a base64 encoded image with the\n",
    "filetype as a prefix (e.g. `data:image/png;base64,{YOUR_BASE64_ENCODED_DATA}`).\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cb65e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"msg_01AuGpm6xbacTwoUFdNiCnzu\",\n",
      "  \"content\": \"The image shows a hot dog. It consists of a cylindrical bread roll or bun that has been sliced lengthwise, revealing the bright red hot dog sausage filling inside. The hot dog sausage appears to be made from seasoned and smoked meat. This classic fast food item is a popular snack or meal, commonly enjoyed at sporting events, cookouts, and casual eateries.\",\n",
      "  \"additional_kwargs\": {\n",
      "    \"id\": \"msg_01AuGpm6xbacTwoUFdNiCnzu\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 276,\n",
      "      \"output_tokens\": 88\n",
      "    }\n",
      "  },\n",
      "  \"response_metadata\": {\n",
      "    \"id\": \"msg_01AuGpm6xbacTwoUFdNiCnzu\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 276,\n",
      "      \"output_tokens\": 88\n",
      "    },\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 276,\n",
      "    \"output_tokens\": 88,\n",
      "    \"total_tokens\": 364\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fs from \"fs/promises\";\n",
    "\n",
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const imageData = await fs.readFile(\"../../../../../examples/hotdog.jpg\");\n",
    "const llm2 = new ChatAnthropic({\n",
    "  model: \"claude-3-sonnet-20240229\",\n",
    "});\n",
    "const multimodalMessage = new HumanMessage({\n",
    "  content: [\n",
    "    {\n",
    "      type: \"text\",\n",
    "      text: \"What's in this image?\",\n",
    "    },\n",
    "    {\n",
    "      type: \"image_url\",\n",
    "      image_url: {\n",
    "        url: `data:image/jpeg;base64,${imageData.toString(\"base64\")}`,\n",
    "      },\n",
    "    },\n",
    "  ],\n",
    "});\n",
    "\n",
    "await llm2.invoke([multimodalMessage]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c14fbc0",
   "metadata": {},
   "source": [
    "See [the official docs](https://docs.anthropic.com/claude/docs/vision#what-image-file-types-does-claude-support)\n",
    "for a complete list of supported file types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bce78a1",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "Anthropic models can be used to power [LangGraph.js](https://langchain-ai.github.io/langgraphjs/) agents:\n",
    "\n",
    "```{=mdx}\n",
    "<Npm2Yarn>\n",
    "  @langchain/langgraph\n",
    "</Npm2Yarn>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0648b504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"msg_01Y4nz4gM4LB57WHc3viGgRp\",\n",
      "  \"content\": \"The current weather in San Francisco, CA is 28°C.\",\n",
      "  \"additional_kwargs\": {\n",
      "    \"id\": \"msg_01Y4nz4gM4LB57WHc3viGgRp\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 364,\n",
      "      \"output_tokens\": 18\n",
      "    }\n",
      "  },\n",
      "  \"response_metadata\": {\n",
      "    \"id\": \"msg_01Y4nz4gM4LB57WHc3viGgRp\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 364,\n",
      "      \"output_tokens\": 18\n",
      "    },\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 364,\n",
      "    \"output_tokens\": 18,\n",
      "    \"total_tokens\": 382\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { z } from \"zod\";\n",
    "\n",
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "import { tool } from \"@langchain/core/tools\";\n",
    "import { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const agentModel = new ChatAnthropic({\n",
    "  model: \"claude-3-sonnet-20240229\",\n",
    "  temperature: 0,\n",
    "});\n",
    "\n",
    "const currentWeatherTool = tool(async () => \"28 °C\", {\n",
    "  name: \"get_current_weather\",\n",
    "  description: \"Get the current weather in a given location\",\n",
    "  schema: z.object({\n",
    "    location: z.string().describe(\"The city and state, e.g. San Francisco, CA\"),\n",
    "  }),\n",
    "});\n",
    "\n",
    "const agent = createReactAgent({\n",
    "  llm: agentModel,\n",
    "  tools: [currentWeatherTool],\n",
    "});\n",
    "\n",
    "const agentResult = await agent.invoke({\n",
    "  messages: [\n",
    "    new HumanMessage(\"What's the weather like in SF?\")\n",
    "  ]\n",
    "});\n",
    "\n",
    "console.log(agentResult.messages[agentResult.messages.length - 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d452d4b6",
   "metadata": {},
   "source": [
    "## Custom headers\n",
    "\n",
    "You can pass custom headers in your requests like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41943f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"msg_0131WctMyzmv4myNQeuAituP\",\n",
      "  \"content\": \"The sky appears blue because of the way sunlight interacts with the Earth's atmosphere. Here's a more detailed explanation:\\n\\n- Sunlight is made up of different wavelengths of light, including all the colors of the visible spectrum (red, orange, yellow, green, blue, indigo, violet).\\n\\n- As sunlight passes through the atmosphere, it encounters tiny molecules of oxygen and nitrogen in the air.\\n\\n- These gas molecules are very effective at scattering and deflecting the shorter wavelengths of light, which correspond to the colors in the blue and violet range of the spectrum.\\n\\n- The longer wavelengths of light (reds, oranges) are able to travel more directly through the atmosphere without getting scattered as much.\\n\\n- The scattered blue wavelengths of light get deflected in all directions by the atmospheric gases. This blue light gets scattered about everywhere in the sky, making the sky appear blue from the ground.\\n\\n- The effect is more pronounced with a clear sky during the daytime when more sunlight is entering the atmosphere.\\n\\nSo in essence, the blueness of the sky is caused by the preferable scattering of blue wavelengths of light by the tiny gas molecules present in the Earth's atmosphere.\",\n",
      "  \"additional_kwargs\": {\n",
      "    \"id\": \"msg_0131WctMyzmv4myNQeuAituP\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 13,\n",
      "      \"output_tokens\": 263\n",
      "    }\n",
      "  },\n",
      "  \"response_metadata\": {\n",
      "    \"id\": \"msg_0131WctMyzmv4myNQeuAituP\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 13,\n",
      "      \"output_tokens\": 263\n",
      "    },\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 13,\n",
      "    \"output_tokens\": 263,\n",
      "    \"total_tokens\": 276\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "\n",
    "const llmWithCustomHeaders = new ChatAnthropic({\n",
    "  model: \"claude-3-sonnet-20240229\",\n",
    "  maxTokens: 1024,\n",
    "  clientOptions: {\n",
    "    defaultHeaders: {\n",
    "      \"X-Api-Key\": process.env.ANTHROPIC_API_KEY,\n",
    "    },\n",
    "  },\n",
    "});\n",
    "\n",
    "await llmWithCustomHeaders.invoke(\"Why is the sky blue?\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985c4b4b",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "The following example demonstrates [how to call tools](/docs/how_to/tool_calling) with Anthropic models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ce56548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    name: 'calculator',\n",
      "    args: { number1: 2, number2: 2, operation: 'add' },\n",
      "    id: 'toolu_01Wjh2R15J945ErnGQ79UrpA',\n",
      "    type: 'tool_call'\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { z } from \"zod\";\n",
    "\n",
    "const calculatorSchema = z.object({\n",
    "  operation: z\n",
    "    .enum([\"add\", \"subtract\", \"multiply\", \"divide\"])\n",
    "    .describe(\"The type of operation to execute.\"),\n",
    "  number1: z.number().describe(\"The first number to operate on.\"),\n",
    "  number2: z.number().describe(\"The second number to operate on.\"),\n",
    "});\n",
    "\n",
    "const calculatorTool = {\n",
    "  name: \"calculator\",\n",
    "  description: \"A simple calculator tool\",\n",
    "  input_schema: zodToJsonSchema(calculatorSchema),\n",
    "};\n",
    "\n",
    "const toolCallingLlm = new ChatAnthropic({\n",
    "  model: \"claude-3-haiku-20240307\",\n",
    "}).bindTools([calculatorTool]);\n",
    "\n",
    "const toolPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\n",
    "    \"system\",\n",
    "    \"You are a helpful assistant who always needs to use a calculator.\",\n",
    "  ],\n",
    "  [\"human\", \"{input}\"],\n",
    "]);\n",
    "\n",
    "// Chain your prompt and model together\n",
    "const toolCallChain = toolPrompt.pipe(toolCallingLlm);\n",
    "\n",
    "const toolResponse = await toolCallChain.invoke({\n",
    "  input: \"What is 2 + 2?\",\n",
    "});\n",
    "\n",
    "toolResponse.tool_calls;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15253085",
   "metadata": {},
   "source": [
    "### `withStructuredOutput`\n",
    "\n",
    "If you just need to get structured output from the model, Anthropic models support the [`.withStructuredOutput()`](/docs/how_to/structured_output/#the-.withstructuredoutput-method) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e466d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  setup: \"Why don't cats play poker in the jungle?\",\n",
      "  punchline: 'Too many cheetahs!',\n",
      "  rating: 7\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { z } from \"zod\";\n",
    "\n",
    "const joke = z.object({\n",
    "  setup: z.string().describe(\"The setup of the joke\"),\n",
    "  punchline: z.string().describe(\"The punchline to the joke\"),\n",
    "  rating: z.number().optional().describe(\"How funny the joke is, from 1 to 10\"),\n",
    "});\n",
    "\n",
    "const modelForStructuredOutput = new ChatAnthropic({\n",
    "  model: \"claude-3-haiku-20240307\",\n",
    "})\n",
    "\n",
    "const structuredLlm = modelForStructuredOutput.withStructuredOutput(joke);\n",
    "\n",
    "await structuredLlm.invoke(\"Tell me a joke about cats\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all ChatAnthropic features and configurations head to the API reference: https://api.js.langchain.com/classes/langchain_anthropic.ChatAnthropic.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
