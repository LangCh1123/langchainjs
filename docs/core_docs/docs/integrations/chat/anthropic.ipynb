{
 "cells": [
  {
   "cell_type": "raw",
   "id": "afaf8039",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: ChatAnthropic\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f1e0d",
   "metadata": {},
   "source": [
    "# ChatAnthropic\n",
    "\n",
    "This will help you getting started with ChatAnthropic [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatAnthropic features and configurations head to the [API reference](https://api.js.langchain.com/classes/langchain_anthropic.ChatAnthropic.html).\n",
    "\n",
    "## Overview\n",
    "### Integration details\n",
    "\n",
    "| Class | Package | Local | Serializable | [PY support](https://python.langchain.com/docs/integrations/chat/anthropic/) | Package downloads | Package latest |\n",
    "| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\n",
    "| [ChatAnthropic](https://api.js.langchain.com/classes/langchain_anthropic.ChatAnthropic.html) | [@langchain/anthropic](https://api.js.langchain.com/modules/langchain_anthropic.html) | ❌ | ✅ | ✅ | ![NPM - Downloads](https://img.shields.io/npm/dm/@langchain/anthropic?style=flat-square&label=%20) | ![NPM - Version](https://img.shields.io/npm/v/@langchain/anthropic?style=flat-square&label=%20) |\n",
    "\n",
    "### Model features\n",
    "| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\n",
    "| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: |\n",
    "| ✅ | ✅ | ❌ | ✅ | ❌ | ❌ | ✅ | ✅ | ❌ | \n",
    "\n",
    "## Setup\n",
    "\n",
    "You'll need to sign up and obtain an [Anthropic API key](https://www.anthropic.com/), and install the `@langchain/anthropic` integration package.\n",
    "\n",
    "### Credentials\n",
    "\n",
    "Head to [Anthropic's website](https://www.anthropic.com/) to sign up to Anthropic and generate an API key. Once you've done this set the `ANTHROPIC_API_KEY` environment variable:\n",
    "\n",
    "```{=mdx}\n",
    "\n",
    "```bash\n",
    "export ANTHROPIC_API_KEY=\"your-api-key\"\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee0c4b-9764-423a-9dbf-95129e185210",
   "metadata": {},
   "source": [
    "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n",
    "\n",
    "```{=mdx}\n",
    "\n",
    "```bash\n",
    "# export LANGCHAIN_TRACING_V2=\"true\"\n",
    "# export LANGCHAIN_API_KEY=\"your-api-key\"\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730d6a1-c893-4840-9817-5e5251676d5d",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "The LangChain ChatAnthropic integration lives in the `@langchain/anthropic` package:\n",
    "\n",
    "```{=mdx}\n",
    "\n",
    "```bash npm2yarn\n",
    "npm i @langchain/anthropic\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cde65-254d-4219-a441-068766c0d4b5",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Now we can instantiate our model object and generate chat completions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb09c344-1836-4e0c-acf8-11d13ac1dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatAnthropic } from \"@langchain/anthropic\" \n",
    "\n",
    "const llm = new ChatAnthropic({\n",
    "    model: \"claude-3-haiku-20240307\",\n",
    "    temperature: 0,\n",
    "    maxTokens: undefined,\n",
    "    maxRetries: 2,\n",
    "    // other params...\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f3e15",
   "metadata": {},
   "source": [
    "## Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e0dbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"msg_01M9yt3aSqKJKM1RnZF4f44Q\",\n",
      "  \"content\": \"Voici la traduction en français :\\n\\nJ'adore la programmation.\",\n",
      "  \"additional_kwargs\": {\n",
      "    \"id\": \"msg_01M9yt3aSqKJKM1RnZF4f44Q\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 29,\n",
      "      \"output_tokens\": 20\n",
      "    }\n",
      "  },\n",
      "  \"response_metadata\": {\n",
      "    \"id\": \"msg_01M9yt3aSqKJKM1RnZF4f44Q\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 29,\n",
      "      \"output_tokens\": 20\n",
      "    },\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 29,\n",
      "    \"output_tokens\": 20,\n",
      "    \"total_tokens\": 49\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const aiMsg = await llm.invoke([\n",
    "    [\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ],\n",
    "    [\"human\", \"I love programming.\"],\n",
    "])\n",
    "aiMsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d86145b3-bfef-46e8-b227-4dda5c9c2705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici la traduction en français :\n",
      "\n",
      "J'adore la programmation.\n"
     ]
    }
   ],
   "source": [
    "console.log(aiMsg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2bfc0-7e78-4528-a73f-499ac150dca8",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "We can [chain](/docs/how_to/sequence/) our model with a prompt template like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e197d1d7-a070-4c96-9f8a-a0e86d046e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"msg_012gUKUG65teaois31W3bfGF\",\n",
      "  \"content\": \"Ich liebe das Programmieren.\",\n",
      "  \"additional_kwargs\": {\n",
      "    \"id\": \"msg_012gUKUG65teaois31W3bfGF\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 23,\n",
      "      \"output_tokens\": 11\n",
      "    }\n",
      "  },\n",
      "  \"response_metadata\": {\n",
      "    \"id\": \"msg_012gUKUG65teaois31W3bfGF\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 23,\n",
      "      \"output_tokens\": 11\n",
      "    },\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 23,\n",
      "    \"output_tokens\": 11,\n",
      "    \"total_tokens\": 34\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\"\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromMessages(\n",
    "    [\n",
    "        [\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ],\n",
    "        [\"human\", \"{input}\"],\n",
    "    ]\n",
    ")\n",
    "\n",
    "const chain = prompt.pipe(llm);\n",
    "await chain.invoke(\n",
    "    {\n",
    "        input_language: \"English\",\n",
    "        output_language: \"German\",\n",
    "        input: \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ee55bc-ffc8-4cfa-801c-993953a08cfd",
   "metadata": {},
   "source": [
    "## Multimodal inputs\n",
    "\n",
    "Claude-3 models support image multimodal inputs. The passed input must be a base64 encoded image with the\n",
    "filetype as a prefix (e.g. `data:image/png;base64,{YOUR_BASE64_ENCODED_DATA}`).\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cb65e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"msg_01AuGpm6xbacTwoUFdNiCnzu\",\n",
      "  \"content\": \"The image shows a hot dog. It consists of a cylindrical bread roll or bun that has been sliced lengthwise, revealing the bright red hot dog sausage filling inside. The hot dog sausage appears to be made from seasoned and smoked meat. This classic fast food item is a popular snack or meal, commonly enjoyed at sporting events, cookouts, and casual eateries.\",\n",
      "  \"additional_kwargs\": {\n",
      "    \"id\": \"msg_01AuGpm6xbacTwoUFdNiCnzu\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 276,\n",
      "      \"output_tokens\": 88\n",
      "    }\n",
      "  },\n",
      "  \"response_metadata\": {\n",
      "    \"id\": \"msg_01AuGpm6xbacTwoUFdNiCnzu\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 276,\n",
      "      \"output_tokens\": 88\n",
      "    },\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 276,\n",
      "    \"output_tokens\": 88,\n",
      "    \"total_tokens\": 364\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import * as fs from \"node:fs/promises\";\n",
    "\n",
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const imageData2 = await fs.readFile(\"../../../../../examples/hotdog.jpg\");\n",
    "const llm2 = new ChatAnthropic({\n",
    "  model: \"claude-3-sonnet-20240229\",\n",
    "});\n",
    "const message2 = new HumanMessage({\n",
    "  content: [\n",
    "    {\n",
    "      type: \"text\",\n",
    "      text: \"What's in this image?\",\n",
    "    },\n",
    "    {\n",
    "      type: \"image_url\",\n",
    "      image_url: {\n",
    "        url: `data:image/jpeg;base64,${imageData2.toString(\"base64\")}`,\n",
    "      },\n",
    "    },\n",
    "  ],\n",
    "});\n",
    "\n",
    "await llm2.invoke([message2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c14fbc0",
   "metadata": {},
   "source": [
    "See [the official docs](https://docs.anthropic.com/claude/docs/vision#what-image-file-types-does-claude-support)\n",
    "for a complete list of supported file types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bce78a1",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "Anthropic models that support tool calling can be used in the Tool Calling agent. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0648b504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    index: 0,\n",
      "    type: 'text',\n",
      "    text: '\\n\\nThe current weather in San Francisco, CA is 28°C.'\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import { z } from \"zod\";\n",
    "\n",
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "import { tool } from \"@langchain/core/tools\";\n",
    "import { AgentExecutor, createToolCallingAgent } from \"langchain/agents\";\n",
    "\n",
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const llm3 = new ChatAnthropic({\n",
    "  model: \"claude-3-sonnet-20240229\",\n",
    "  temperature: 0,\n",
    "});\n",
    "\n",
    "// Prompt template must have \"input\" and \"agent_scratchpad input variables\"\n",
    "const prompt3 = ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", \"You are a helpful assistant\"],\n",
    "  [\"placeholder\", \"{chat_history}\"],\n",
    "  [\"human\", \"{input}\"],\n",
    "  [\"placeholder\", \"{agent_scratchpad}\"],\n",
    "]);\n",
    "\n",
    "const currentWeatherTool3 = tool(async () => \"28 °C\", {\n",
    "  name: \"get_current_weather\",\n",
    "  description: \"Get the current weather in a given location\",\n",
    "  schema: z.object({\n",
    "    location: z.string().describe(\"The city and state, e.g. San Francisco, CA\"),\n",
    "  }),\n",
    "});\n",
    "\n",
    "const agent3 = createToolCallingAgent({\n",
    "  llm: llm3,\n",
    "  tools: [currentWeatherTool3],\n",
    "  prompt: prompt3,\n",
    "});\n",
    "\n",
    "const agentExecutor3 = new AgentExecutor({\n",
    "  agent: agent3,\n",
    "  tools: [currentWeatherTool3],\n",
    "});\n",
    "\n",
    "const input3 = \"What's the weather like in SF?\";\n",
    "const result3 = await agentExecutor3.invoke({ input: input3 });\n",
    "\n",
    "console.log(result3.output);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d452d4b6",
   "metadata": {},
   "source": [
    "## Custom headers\n",
    "\n",
    "You can pass custom headers in your requests like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41943f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"msg_013Ft3kN62gNtiMWRqg6xxt8\",\n",
      "  \"content\": \"The sky appears blue due to a phenomenon called Rayleigh scattering. Here's a brief explanation:\\n\\n1) Sunlight is made up of different wavelengths of light, including the visible spectrum that we see as colors.\\n\\n2) As sunlight passes through the Earth's atmosphere, the different wavelengths of light interact with the gas molecules in the air.\\n\\n3) The shorter wavelengths of light, such as the blue and violet colors, get scattered more easily by the tiny gas molecules. This is because the wavelengths are similar in size to the molecules.\\n\\n4) The longer wavelengths of light, such as red and orange, get scattered much less by the gas molecules and travel more directly through the atmosphere.\\n\\n5) The blue wavelengths that are scattered in different directions become scattered across the entire sky, making the sky appear blue to our eyes.\\n\\n6) During sunrise and sunset, the sun's rays travel through more atmosphere before reaching our eyes, causing the blue light to get scattered away and allowing more of the red/orange wavelengths to pass through, giving those colors in the sky.\\n\\nSo in essence, the abundant scattering of blue light by the gas molecules in the atmosphere is what causes the sky to appear blue during the daytime.\",\n",
      "  \"additional_kwargs\": {\n",
      "    \"id\": \"msg_013Ft3kN62gNtiMWRqg6xxt8\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 13,\n",
      "      \"output_tokens\": 272\n",
      "    }\n",
      "  },\n",
      "  \"response_metadata\": {\n",
      "    \"id\": \"msg_013Ft3kN62gNtiMWRqg6xxt8\",\n",
      "    \"model\": \"claude-3-sonnet-20240229\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 13,\n",
      "      \"output_tokens\": 272\n",
      "    },\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\"\n",
      "  },\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 13,\n",
      "    \"output_tokens\": 272,\n",
      "    \"total_tokens\": 285\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "\n",
    "const llm4 = new ChatAnthropic({\n",
    "  model: \"claude-3-sonnet-20240229\",\n",
    "  maxTokens: 1024,\n",
    "  clientOptions: {\n",
    "    defaultHeaders: {\n",
    "      \"X-Api-Key\": process.env.ANTHROPIC_API_KEY,\n",
    "    },\n",
    "  },\n",
    "});\n",
    "\n",
    "const res4 = await llm4.invoke(\"Why is the sky blue?\");\n",
    "\n",
    "console.log(res4);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985c4b4b",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "The Anthropic API supports tool calling, along with multi-tool calling. The following examples demonstrate how to call tools:\n",
    "\n",
    "### Single Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ce56548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"msg_01XPUHrR4sNCqPr1i9zcsAsg\",\n",
      "  \"content\": [\n",
      "    {\n",
      "      \"type\": \"text\",\n",
      "      \"text\": \"Okay, let me use the calculator tool to find the answer:\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"tool_use\",\n",
      "      \"id\": \"toolu_01MhUVuUedc1drBKLarhedFZ\",\n",
      "      \"name\": \"calculator\",\n",
      "      \"input\": {\n",
      "        \"number1\": 2,\n",
      "        \"number2\": 2,\n",
      "        \"operation\": \"add\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"additional_kwargs\": {\n",
      "    \"id\": \"msg_01XPUHrR4sNCqPr1i9zcsAsg\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"tool_use\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 449,\n",
      "      \"output_tokens\": 101\n",
      "    }\n",
      "  },\n",
      "  \"response_metadata\": {\n",
      "    \"id\": \"msg_01XPUHrR4sNCqPr1i9zcsAsg\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"tool_use\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 449,\n",
      "      \"output_tokens\": 101\n",
      "    },\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\"\n",
      "  },\n",
      "  \"tool_calls\": [\n",
      "    {\n",
      "      \"name\": \"calculator\",\n",
      "      \"args\": {\n",
      "        \"number1\": 2,\n",
      "        \"number2\": 2,\n",
      "        \"operation\": \"add\"\n",
      "      },\n",
      "      \"id\": \"toolu_01MhUVuUedc1drBKLarhedFZ\",\n",
      "      \"type\": \"tool_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 449,\n",
      "    \"output_tokens\": 101,\n",
      "    \"total_tokens\": 550\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { z } from \"zod\";\n",
    "import { zodToJsonSchema } from \"zod-to-json-schema\";\n",
    "\n",
    "const calculatorSchema5 = z.object({\n",
    "  operation: z\n",
    "    .enum([\"add\", \"subtract\", \"multiply\", \"divide\"])\n",
    "    .describe(\"The type of operation to execute.\"),\n",
    "  number1: z.number().describe(\"The first number to operate on.\"),\n",
    "  number2: z.number().describe(\"The second number to operate on.\"),\n",
    "});\n",
    "\n",
    "const tool5 = {\n",
    "  name: \"calculator\",\n",
    "  description: \"A simple calculator tool\",\n",
    "  input_schema: zodToJsonSchema(calculatorSchema5),\n",
    "};\n",
    "\n",
    "const llm5 = new ChatAnthropic({\n",
    "  apiKey: process.env.ANTHROPIC_API_KEY,\n",
    "  model: \"claude-3-haiku-20240307\",\n",
    "}).bind({\n",
    "  tools: [tool5],\n",
    "});\n",
    "\n",
    "const prompt5 = ChatPromptTemplate.fromMessages([\n",
    "  [\n",
    "    \"system\",\n",
    "    \"You are a helpful assistant who always needs to use a calculator.\",\n",
    "  ],\n",
    "  [\"human\", \"{input}\"],\n",
    "]);\n",
    "\n",
    "// Chain your prompt and model together\n",
    "const chain5 = prompt5.pipe(llm5);\n",
    "\n",
    "const response5 = await chain5.invoke({\n",
    "  input: \"What is 2 + 2?\",\n",
    "});\n",
    "console.log(response5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e91f97b",
   "metadata": {},
   "source": [
    "### Forced tool calling\n",
    "\n",
    "In this example we'll provide the model with two tools:\n",
    "\n",
    "- `calculator`\n",
    "- `get_weather`\n",
    "\n",
    "Then, when we call `bindTools`, we'll force the model to use the `get_weather` tool by passing the `tool_choice` arg like this:\n",
    "\n",
    "```typescript\n",
    ".bindTools({\n",
    "  tools,\n",
    "  tool_choice: {\n",
    "    type: \"tool\",\n",
    "    name: \"get_weather\",\n",
    "  }\n",
    "});\n",
    "```\n",
    "\n",
    "Finally, we'll invoke the model, but instead of asking about the weather, we'll ask it to do some math.\n",
    "Since we explicitly forced the model to use the `get_weather` tool, it will ignore the input and return the weather information (in this case it returned `<UNKNOWN>`, which is expected.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d6e4828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  \"id\": \"msg_018G4mEZu8KNKtaQxZQ3o8YB\",\n",
      "  \"content\": [\n",
      "    {\n",
      "      \"type\": \"tool_use\",\n",
      "      \"id\": \"toolu_01DS9RwsFKdhHNYmhwPJHdHa\",\n",
      "      \"name\": \"get_weather\",\n",
      "      \"input\": {\n",
      "        \"city\": \"<UNKNOWN>\",\n",
      "        \"state\": \"<UNKNOWN>\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"additional_kwargs\": {\n",
      "    \"id\": \"msg_018G4mEZu8KNKtaQxZQ3o8YB\",\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"tool_use\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 672,\n",
      "      \"output_tokens\": 51\n",
      "    }\n",
      "  },\n",
      "  \"response_metadata\": {\n",
      "    \"id\": \"msg_018G4mEZu8KNKtaQxZQ3o8YB\",\n",
      "    \"model\": \"claude-3-haiku-20240307\",\n",
      "    \"stop_reason\": \"tool_use\",\n",
      "    \"stop_sequence\": null,\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 672,\n",
      "      \"output_tokens\": 51\n",
      "    },\n",
      "    \"type\": \"message\",\n",
      "    \"role\": \"assistant\"\n",
      "  },\n",
      "  \"tool_calls\": [\n",
      "    {\n",
      "      \"name\": \"get_weather\",\n",
      "      \"args\": {\n",
      "        \"city\": \"<UNKNOWN>\",\n",
      "        \"state\": \"<UNKNOWN>\"\n",
      "      },\n",
      "      \"id\": \"toolu_01DS9RwsFKdhHNYmhwPJHdHa\",\n",
      "      \"type\": \"tool_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 672,\n",
      "    \"output_tokens\": 51,\n",
      "    \"total_tokens\": 723\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { z } from \"zod\";\n",
    "import { zodToJsonSchema } from \"zod-to-json-schema\";\n",
    "\n",
    "const calculatorSchema6 = z.object({\n",
    "  operation: z\n",
    "    .enum([\"add\", \"subtract\", \"multiply\", \"divide\"])\n",
    "    .describe(\"The type of operation to execute.\"),\n",
    "  number1: z.number().describe(\"The first number to operate on.\"),\n",
    "  number2: z.number().describe(\"The second number to operate on.\"),\n",
    "});\n",
    "\n",
    "const weatherSchema6 = z.object({\n",
    "  city: z.string().describe(\"The city to get the weather from\"),\n",
    "  state: z.string().optional().describe(\"The state to get the weather from\"),\n",
    "});\n",
    "\n",
    "const tools6 = [\n",
    "  {\n",
    "    name: \"calculator\",\n",
    "    description: \"A simple calculator tool\",\n",
    "    input_schema: zodToJsonSchema(calculatorSchema6),\n",
    "  },\n",
    "  {\n",
    "    name: \"get_weather\",\n",
    "    description:\n",
    "      \"Get the weather of a specific location and return the temperature in Celsius.\",\n",
    "    input_schema: zodToJsonSchema(weatherSchema6),\n",
    "  },\n",
    "];\n",
    "\n",
    "const llm6 = new ChatAnthropic({\n",
    "  apiKey: process.env.ANTHROPIC_API_KEY,\n",
    "  model: \"claude-3-haiku-20240307\",\n",
    "}).bind({\n",
    "  tools: tools6,\n",
    "  tool_choice: {\n",
    "    type: \"tool\",\n",
    "    name: \"get_weather\",\n",
    "  },\n",
    "});\n",
    "\n",
    "const prompt6 = ChatPromptTemplate.fromMessages([\n",
    "  [\n",
    "    \"system\",\n",
    "    \"You are a helpful assistant who always needs to use a calculator.\",\n",
    "  ],\n",
    "  [\"human\", \"{input}\"],\n",
    "]);\n",
    "\n",
    "// Chain your prompt and model together\n",
    "const chain6 = prompt6.pipe(llm6);\n",
    "\n",
    "const response6 = await chain6.invoke({\n",
    "  input: \"What is the sum of 2725 and 273639\",\n",
    "});\n",
    "\n",
    "console.log(response6);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa777bc",
   "metadata": {},
   "source": [
    "The `tool_choice` argument has three possible values:\n",
    "\n",
    "- `{ type: \"tool\", name: \"tool_name\" }` | `string` - Forces the model to use the specified tool. If passing a single string, it will be treated as the tool name.\n",
    "- `\"any\"` - Allows the model to choose the tool, but still forcing it to choose at least one.\n",
    "- `\"auto\"` - The default value. Allows the model to select any tool, or none."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15253085",
   "metadata": {},
   "source": [
    "### `withStructuredOutput`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e466d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ operation: 'add', number1: 2, number2: 2 }\n"
     ]
    }
   ],
   "source": [
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { z } from \"zod\";\n",
    "\n",
    "const calculatorSchema7 = z\n",
    "  .object({\n",
    "    operation: z\n",
    "      .enum([\"add\", \"subtract\", \"multiply\", \"divide\"])\n",
    "      .describe(\"The type of operation to execute.\"),\n",
    "    number1: z.number().describe(\"The first number to operate on.\"),\n",
    "    number2: z.number().describe(\"The second number to operate on.\"),\n",
    "  })\n",
    "  .describe(\"A simple calculator tool\");\n",
    "\n",
    "const llm7 = new ChatAnthropic({\n",
    "  apiKey: process.env.ANTHROPIC_API_KEY,\n",
    "  model: \"claude-3-haiku-20240307\",\n",
    "});\n",
    "\n",
    "// Pass the schema and tool name to the withStructuredOutput method\n",
    "const modelWithTool7 = llm7.withStructuredOutput(calculatorSchema7);\n",
    "\n",
    "const prompt7 = ChatPromptTemplate.fromMessages([\n",
    "  [\n",
    "    \"system\",\n",
    "    \"You are a helpful assistant who always needs to use a calculator.\",\n",
    "  ],\n",
    "  [\"human\", \"{input}\"],\n",
    "]);\n",
    "\n",
    "// Chain your prompt and model together\n",
    "const chain7 = prompt7.pipe(modelWithTool7);\n",
    "\n",
    "const response7 = await chain7.invoke({\n",
    "  input: \"What is 2 + 2?\",\n",
    "});\n",
    "console.log(response7);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4973b265",
   "metadata": {},
   "source": [
    "You can supply a \"name\" field to give the LLM additional context around what you are trying to generate. You can also pass `includeRaw` to get the raw message back from the model too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "951c5352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  raw: AIMessage {\n",
      "    \"id\": \"msg_01TrkHbEkioCYNHQhqxw5unu\",\n",
      "    \"content\": [\n",
      "      {\n",
      "        \"type\": \"tool_use\",\n",
      "        \"id\": \"toolu_01XMrGHXeSVTfSw1oKFZokzG\",\n",
      "        \"name\": \"calculator\",\n",
      "        \"input\": {\n",
      "          \"number1\": 2,\n",
      "          \"number2\": 2,\n",
      "          \"operation\": \"add\"\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    \"additional_kwargs\": {\n",
      "      \"id\": \"msg_01TrkHbEkioCYNHQhqxw5unu\",\n",
      "      \"type\": \"message\",\n",
      "      \"role\": \"assistant\",\n",
      "      \"model\": \"claude-3-haiku-20240307\",\n",
      "      \"stop_reason\": \"tool_use\",\n",
      "      \"stop_sequence\": null,\n",
      "      \"usage\": {\n",
      "        \"input_tokens\": 552,\n",
      "        \"output_tokens\": 69\n",
      "      }\n",
      "    },\n",
      "    \"response_metadata\": {\n",
      "      \"id\": \"msg_01TrkHbEkioCYNHQhqxw5unu\",\n",
      "      \"model\": \"claude-3-haiku-20240307\",\n",
      "      \"stop_reason\": \"tool_use\",\n",
      "      \"stop_sequence\": null,\n",
      "      \"usage\": {\n",
      "        \"input_tokens\": 552,\n",
      "        \"output_tokens\": 69\n",
      "      },\n",
      "      \"type\": \"message\",\n",
      "      \"role\": \"assistant\"\n",
      "    },\n",
      "    \"tool_calls\": [\n",
      "      {\n",
      "        \"name\": \"calculator\",\n",
      "        \"args\": {\n",
      "          \"number1\": 2,\n",
      "          \"number2\": 2,\n",
      "          \"operation\": \"add\"\n",
      "        },\n",
      "        \"id\": \"toolu_01XMrGHXeSVTfSw1oKFZokzG\",\n",
      "        \"type\": \"tool_call\"\n",
      "      }\n",
      "    ],\n",
      "    \"invalid_tool_calls\": [],\n",
      "    \"usage_metadata\": {\n",
      "      \"input_tokens\": 552,\n",
      "      \"output_tokens\": 69,\n",
      "      \"total_tokens\": 621\n",
      "    }\n",
      "  },\n",
      "  parsed: { operation: 'add', number1: 2, number2: 2 }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const includeRawModel7 = llm7.withStructuredOutput(calculatorSchema7, {\n",
    "  name: \"calculator\",\n",
    "  includeRaw: true,\n",
    "});\n",
    "const includeRawChain7 = prompt7.pipe(includeRawModel7);\n",
    "\n",
    "const includeRawResponse7 = await includeRawChain7.invoke({\n",
    "  input: \"What is 2 + 2?\",\n",
    "});\n",
    "\n",
    "console.log(includeRawResponse7);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all ChatAnthropic features and configurations head to the API reference: https://api.js.langchain.com/classes/langchain_anthropic.ChatAnthropic.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
