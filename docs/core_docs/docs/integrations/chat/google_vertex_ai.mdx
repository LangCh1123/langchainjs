---
sidebar_label: Google Vertex AI
keywords: [gemini, gemini-pro, ChatVertexAI, vertex]
---

import CodeBlock from "@theme/CodeBlock";

# ChatVertexAI

LangChain.js supports Google Vertex AI chat models as an integration.
It supports two different methods of authentication based on whether you're running
in a Node environment or a web environment.

## Setup

### Node

To call Vertex AI models in Node, you'll need to install the `@langchain/google-vertexai` package:

import IntegrationInstallTooltip from "@mdx_components/integration_install_tooltip.mdx";

<IntegrationInstallTooltip></IntegrationInstallTooltip>

```bash npm2yarn
npm install @langchain/google-vertexai
```

import UnifiedModelParamsTooltip from "@mdx_components/unified_model_params_tooltip.mdx";

<UnifiedModelParamsTooltip></UnifiedModelParamsTooltip>

You should make sure the Vertex AI API is
enabled for the relevant project and that you've authenticated to
Google Cloud using one of these methods:

- You are logged into an account (using `gcloud auth application-default login`)
  permitted to that project.
- You are running on a machine using a service account that is permitted
  to the project.
- You have downloaded the credentials for a service account that is permitted
  to the project and set the `GOOGLE_APPLICATION_CREDENTIALS` environment
  variable to the path of this file.

<IntegrationInstallTooltip></IntegrationInstallTooltip>

```bash npm2yarn
npm install @langchain/google-vertexai
```

### Web

To call Vertex AI models in web environments (like Edge functions), you'll need to install
the `@langchain/google-vertexai-web` package:

```bash npm2yarn
npm install @langchain/google-vertexai-web
```

Then, you'll need to add your service account credentials directly as a `GOOGLE_VERTEX_AI_WEB_CREDENTIALS` environment variable:

```
GOOGLE_VERTEX_AI_WEB_CREDENTIALS={"type":"service_account","project_id":"YOUR_PROJECT-12345",...}
```

Lastly, you may also pass your credentials directly in code like this:

```typescript
import { ChatVertexAI } from "@langchain/google-vertexai-web";

const model = new ChatVertexAI({
  authOptions: {
    credentials: {"type":"service_account","project_id":"YOUR_PROJECT-12345",...},
  },
});
```

## Usage

The entire family of `gemini` models are available by specifying the `modelName` parameter.

For example:

import ChatVertexAI from "@examples/models/chat/integration_googlevertexai.ts";

<CodeBlock language="typescript">{ChatVertexAI}</CodeBlock>

:::tip
See the LangSmith trace for the example above [here](https://smith.langchain.com/public/9403290d-1ca6-41e5-819c-f3ec233194c5/r).
:::

## Multi-modal

The Gemini API can process multi modal inputs. The example below demonstrates how to do this:

import MultiModalVertexAI from "@examples/models/chat/integration_googlevertexai-multimodal.ts";

<CodeBlock language="typescript">{MultiModalVertexAI}</CodeBlock>

:::tip
See the LangSmith trace for the example above [here](https://smith.langchain.com/public/4cb2707d-bcf8-417e-8965-310b3045eb62/r).
:::

### Streaming

`ChatVertexAI` also supports streaming in multiple chunks for faster responses:

import ChatVertexAIStreaming from "@examples/models/chat/integration_googlevertexai-streaming.ts";

<CodeBlock language="typescript">{ChatVertexAIStreaming}</CodeBlock>

:::tip
See the LangSmith trace for the example above [here](https://smith.langchain.com/public/011c26dc-b7db-4fad-b0f2-3653f41a7667/r).
:::

### Tool calling

`ChatVertexAI` also supports calling the model with a tool:

import ChatVertexAITool from "@examples/models/chat/integration_googlevertexai-tools.ts";

<CodeBlock language="typescript">{ChatVertexAITool}</CodeBlock>

:::tip
See the LangSmith trace for the example above [here](https://smith.langchain.com/public/e6714fb3-ef24-447c-810d-7ff2c80c7db4/r).
:::

### `withStructuredOutput`

Alternatively, you can also use the `withStructuredOutput` method:

import ChatVertexAIWSO from "@examples/models/chat/integration_googlevertexai-wso.ts";

<CodeBlock language="typescript">{ChatVertexAIWSO}</CodeBlock>

:::tip
See the LangSmith trace for the example above [here](https://smith.langchain.com/public/d7b9860a-a761-4f76-ba57-195759eb38e7/r).
:::

### VertexAI tools agent

The Gemini family of models not only support tool calling, but can also be used in the Tool Calling agent.
Here's an example:

import AgentsExample from "@examples/models/chat/chat_vertexai_agents.ts";

<CodeBlock language="typescript">{AgentsExample}</CodeBlock>

:::tip
See the LangSmith trace for the agent example above [here](https://smith.langchain.com/public/5615ee35-ba76-433b-8639-9b321cb6d4bf/r).
:::
