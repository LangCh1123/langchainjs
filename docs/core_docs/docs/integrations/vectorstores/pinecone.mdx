---
sidebar_class_name: node-only
---

# Pinecone

:::tip Compatibility
Only available on Node.js.
:::

You can use [Pinecone](https://www.pinecone.io/) vectorstores with LangChain.
To get started, install the integration package and the official Pinecone SDK with:

import IntegrationInstallTooltip from "@mdx_components/integration_install_tooltip.mdx";

<IntegrationInstallTooltip></IntegrationInstallTooltip>

```bash npm2yarn
npm install -S @langchain/pinecone @pinecone-database/pinecone
```

The below examples use OpenAI embeddings, but you can swap in whichever provider you'd like.
Keep in mind different embeddings models may have a different number of dimensions:

```bash npm2yarn
npm install -S @langchain/openai
```

## Index docs

import CodeBlock from "@theme/CodeBlock";
import IndexExample from "@examples/indexes/vector_stores/pinecone/index_docs.ts";

<CodeBlock language="typescript">{IndexExample}</CodeBlock>

## Query docs

import QueryExample from "@examples/indexes/vector_stores/pinecone/query_docs.ts";

<CodeBlock language="typescript">{QueryExample}</CodeBlock>

## Delete docs

import DeleteExample from "@examples/indexes/vector_stores/pinecone/delete_docs.ts";

<CodeBlock language="typescript">{DeleteExample}</CodeBlock>

## Maximal marginal relevance search

Pinecone supports maximal marginal relevance search, which takes a combination of documents
that are most similar to the inputs, then reranks and optimizes for diversity.

```typescript
import { Pinecone } from "@pinecone-database/pinecone";
import { VectorDBQAChain } from "langchain/chains";
import { OpenAIEmbeddings } from "@langchain/openai";
import { OpenAI } from "@langchain/openai";
import { PineconeStore } from "langchain/vectorstores/pinecone";

// Instantiate a new Pinecone client, which will automatically read the
// env vars: PINECONE_API_KEY and PINECONE_ENVIRONMENT which come from
// the Pinecone dashboard at https://app.pinecone.io

const pinecone = new Pinecone();

const pineconeIndex = pinecone.Index(process.env.PINECONE_INDEX);

const vectorStore = await PineconeStore.fromExistingIndex(
  new OpenAIEmbeddings(),
  { pineconeIndex }
);

/* Search the vector DB independently with meta filters */
const results = await vectorStore.maxMarginalRelevance("pinecone", {
  k: 5,
  fetchK: 20, // Default value for the number of initial documents to fetch for reranking.
  // You can pass a filter as well
  // filter: {},
});
console.log(results);
```
