{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1957f5cb",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "sidebar_label: In Memory\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f0986",
   "metadata": {},
   "source": [
    "# MemoryVectorStore\n",
    "\n",
    "MemoryVectorStore is an in-memory, ephemeral vectorstore that stores embeddings in-memory and does an exact, linear search for the most similar embeddings. The default similarity metric is cosine similarity, but can be changed to any of the similarity metrics supported by [ml-distance](https://mljs.github.io/distance/modules/similarity.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fdc060",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To access the in memory vector store you'll need to install the `langchain` integration package.\n",
    "\n",
    "```{=mdx}\n",
    "import IntegrationInstallTooltip from \"@mdx_components/integration_install_tooltip.mdx\";\n",
    "import Npm2Yarn from \"@theme/Npm2Yarn\";\n",
    "\n",
    "<IntegrationInstallTooltip></IntegrationInstallTooltip>\n",
    "\n",
    "<Npm2Yarn>\n",
    "  langchain\n",
    "</Npm2Yarn>\n",
    "```\n",
    "\n",
    "### Credentials\n",
    "\n",
    "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n",
    "\n",
    "```typescript\n",
    "// process.env.LANGCHAIN_TRACING_V2=\"true\"\n",
    "// process.env.LANGCHAIN_API_KEY=\"your-api-key\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93df377e",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "In this example we'll use OpenAIEmbeddings, however you can use any embeddings you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc37144c-208d-4ab3-9f3a-0407a69fe052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import { MemoryVectorStore } from 'langchain/vectorstores/memory'\n",
    "import { OpenAIEmbeddings } from '@langchain/openai'\n",
    "\n",
    "const vectorStore = new MemoryVectorStore(new OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6071d4",
   "metadata": {},
   "source": [
    "## Manage vector store\n",
    "\n",
    "### Add items to vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f5efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { Document } from \"@langchain/core/documents\";\n",
    "\n",
    "const document1 = new Document({\n",
    "  pageContent: \"foo\",\n",
    "  metadata: { source: \"https://example.com\" }\n",
    "});\n",
    "\n",
    "const document2 = new Document({\n",
    "  pageContent: \"bar\",\n",
    "  metadata: { source: \"https://example.com\" }\n",
    "});\n",
    "\n",
    "const document3 = new Document({\n",
    "  pageContent: \"baz\",\n",
    "  metadata: { source: \"https://example.com\" }\n",
    "});\n",
    "\n",
    "const documents = [document1, document2, document3];\n",
    "\n",
    "await vectorStore.addDocuments(documents);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3620501",
   "metadata": {},
   "source": [
    "## Query vector store\n",
    "\n",
    "Once your vector store has been created and the relevant documents have been added you will most likely wish to query it during the running of your chain or agent. \n",
    "\n",
    "### Query directly\n",
    "\n",
    "Performing a simple similarity search can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa0a16fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* foo [{\"source\":\"https://example.com\"}]\n"
     ]
    }
   ],
   "source": [
    "const similaritySearchResults = await vectorStore.similaritySearch(\"thud\", 1, (doc: Document) => doc.metadata.source === \"https://example.com\")\n",
    "\n",
    "for (const doc of similaritySearchResults) {\n",
    "  console.log(`* ${doc.pageContent} [${JSON.stringify(doc.metadata, null)}]`);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed9d733",
   "metadata": {},
   "source": [
    "If you want to execute a similarity search and receive the corresponding scores you can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5efd2eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=0.804] foo [{\"source\":\"https://example.com\"}]\n"
     ]
    }
   ],
   "source": [
    "const similaritySearchWithScoreResults = await vectorStore.similaritySearchWithScore(\"thud\", 1, (doc: Document) => doc.metadata.source === \"https://example.com\")\n",
    "\n",
    "for (const [doc, score] of similaritySearchWithScoreResults) {\n",
    "  console.log(`* [SIM=${score.toFixed(3)}] ${doc.pageContent} [${JSON.stringify(doc.metadata, null)}]`);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c235cdc",
   "metadata": {},
   "source": [
    "### Query by turning into retriever\n",
    "\n",
    "You can also transform the vector store into a retriever for easier usage in your chains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3460093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  Document {\n",
      "    pageContent: 'foo',\n",
      "    metadata: { source: 'https://example.com' },\n",
      "    id: undefined\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: 'baz',\n",
      "    metadata: { source: 'https://example.com' },\n",
      "    id: undefined\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: 'bar',\n",
      "    metadata: { source: 'https://example.com' },\n",
      "    id: undefined\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "const retriever = vectorStore.asRetriever()\n",
    "await retriever.invoke(\"thud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901c75dc",
   "metadata": {},
   "source": [
    "Using retriever in a simple RAG chain:\n",
    "\n",
    "First, select the LLM you'd like to use:\n",
    "\n",
    "```{=mdx}\n",
    "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
    "\n",
    "<ChatModelTabs customVarName=\"llm\" />\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "055f1836",
   "metadata": {},
   "outputs": [],
   "source": [
    "// @lc-docs-hide-cell\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "\n",
    "const llm = new ChatOpenAI({ modelName: \"gpt-4o-mini\", temperature: 0, });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "619b5ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The context includes three terms: \"foo,\" \"baz,\" and \"bar.\" These terms appear to be listed without additional information or explanation. Therefore, the context does not provide any specific details or meaning.\n"
     ]
    }
   ],
   "source": [
    "import { pull } from \"langchain/hub\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "import { RunnablePassthrough, RunnableSequence } from \"@langchain/core/runnables\";\n",
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const prompt = await pull<ChatPromptTemplate>(\"rlm/rag-prompt\");\n",
    "\n",
    "const formatDocs = (docs: any[]) => {\n",
    "  return docs.map(doc => doc.pageContent).join(\"\\n\\n\");\n",
    "};\n",
    "\n",
    "const ragChain = RunnableSequence.from([\n",
    "  {\n",
    "    context: (input: string) => retriever.invoke(input).then(formatDocs),\n",
    "    question: new RunnablePassthrough()\n",
    "  },\n",
    "  prompt,\n",
    "  llm,\n",
    "  new StringOutputParser()\n",
    "])\n",
    "\n",
    "await ragChain.invoke(\"What does the context say?\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069f1b5f",
   "metadata": {},
   "source": [
    "## Create a new index from a loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebf8c09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  Document {\n",
      "    pageContent: 'Foo\\nBar\\nBaz\\n\\n',\n",
      "    metadata: {\n",
      "      source: '../../../../../examples/src/document_loaders/example_data/example.txt'\n",
      "    },\n",
      "    id: undefined\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import { MemoryVectorStore } from \"langchain/vectorstores/memory\";\n",
    "import { OpenAIEmbeddings } from \"@langchain/openai\";\n",
    "import { TextLoader } from \"langchain/document_loaders/fs/text\";\n",
    "\n",
    "// Create docs with a loader\n",
    "const customLoader = new TextLoader(\"../../../../../examples/src/document_loaders/example_data/example.txt\");\n",
    "const customLoaderDocs = await customLoader.load();\n",
    "\n",
    "// Load the docs into the vector store\n",
    "const vectorStoreFromCustomLoader = await MemoryVectorStore.fromDocuments(\n",
    "  customLoaderDocs,\n",
    "  new OpenAIEmbeddings()\n",
    ");\n",
    "\n",
    "// Search for the most similar document\n",
    "const resultFromCustomLoader = await vectorStoreFromCustomLoader.similaritySearch(\"hello world\", 1);\n",
    "\n",
    "console.log(resultFromCustomLoader);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a27244f",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all MemoryVectorStore features and configurations head to the API reference: https://api.python.langchain.com/en/latest/vectorstores/MemoryVectorStore.vectorstores.MemoryVectorStore.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
