{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to pass tool outputs to chat models\n",
    "\n",
    "```{=mdx}\n",
    ":::info Prerequisites\n",
    "This guide assumes familiarity with the following concepts:\n",
    "\n",
    "- [Tools](/docs/concepts/#tools)\n",
    "- [Tool calling](/docs/concepts/#functiontool-calling)\n",
    "\n",
    ":::\n",
    "```\n",
    "\n",
    "If we're using the model-generated tool invocations to actually call tools and want to pass the tool results back to the model, we can do so using `ToolMessage`s and `ToolCall`s. First, let's define some tools and a chat model instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "import { tool } from \"@langchain/core/tools\";\n",
    "\n",
    "const addTool = tool(async ({ a, b }) => {\n",
    "  return a + b;\n",
    "}, {\n",
    "  name: \"add\",\n",
    "  schema: z.object({\n",
    "    a: z.number(),\n",
    "    b: z.number(),\n",
    "  }),\n",
    "  description: \"Adds a and b.\",\n",
    "});\n",
    "\n",
    "const multiplyTool = tool(async ({ a, b }) => {\n",
    "  return a * b;\n",
    "}, {\n",
    "  name: \"multiply\",\n",
    "  schema: z.object({\n",
    "    a: z.number(),\n",
    "    b: z.number(),\n",
    "  }),\n",
    "  description: \"Multiplies a and b.\",\n",
    "});\n",
    "\n",
    "const tools = [addTool, multiplyTool];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{=mdx}\n",
    "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
    "\n",
    "<ChatModelTabs customVarName=\"llm\" />\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we invoke a tool with a `ToolCall`, we'll automatically get back a `ToolMessage` that can be fed back to the model: \n",
    "\n",
    "```{=mdx}\n",
    ":::caution Compatibility\n",
    "\n",
    "This functionality requires `@langchain/core>=0.2.16`. Please see here for a [guide on upgrading](/docs/how_to/installation/#installing-integration-packages).\n",
    "\n",
    ":::\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  HumanMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: 'What is 3 * 12? Also, what is 11 + 49?',\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
      "    content: 'What is 3 * 12? Also, what is 11 + 49?',\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {},\n",
      "    id: undefined\n",
      "  },\n",
      "  AIMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: '',\n",
      "      tool_calls: [Array],\n",
      "      invalid_tool_calls: [],\n",
      "      additional_kwargs: [Object],\n",
      "      id: 'chatcmpl-9llAzVKdHCJkcUCnwGx62bqesSJPB',\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
      "    content: '',\n",
      "    name: undefined,\n",
      "    additional_kwargs: { function_call: undefined, tool_calls: [Array] },\n",
      "    response_metadata: { tokenUsage: [Object], finish_reason: 'tool_calls' },\n",
      "    id: 'chatcmpl-9llAzVKdHCJkcUCnwGx62bqesSJPB',\n",
      "    tool_calls: [ [Object], [Object] ],\n",
      "    invalid_tool_calls: [],\n",
      "    usage_metadata: { input_tokens: 87, output_tokens: 50, total_tokens: 137 }\n",
      "  },\n",
      "  ToolMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: '36',\n",
      "      artifact: undefined,\n",
      "      tool_call_id: 'call_7P5ZjvqWc7jrXjWDkhZ6MU4b',\n",
      "      name: 'multiply',\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
      "    content: '36',\n",
      "    name: 'multiply',\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {},\n",
      "    id: undefined,\n",
      "    tool_call_id: 'call_7P5ZjvqWc7jrXjWDkhZ6MU4b',\n",
      "    artifact: undefined\n",
      "  },\n",
      "  ToolMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: '60',\n",
      "      artifact: undefined,\n",
      "      tool_call_id: 'call_jbyowegkI0coHbnnHs7HLELC',\n",
      "      name: 'add',\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ 'langchain_core', 'messages' ],\n",
      "    content: '60',\n",
      "    name: 'add',\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {},\n",
      "    id: undefined,\n",
      "    tool_call_id: 'call_jbyowegkI0coHbnnHs7HLELC',\n",
      "    artifact: undefined\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const messages = [\n",
    "  new HumanMessage(\"What is 3 * 12? Also, what is 11 + 49?\"),\n",
    "];\n",
    "\n",
    "const aiMessage = await llmWithTools.invoke(messages);\n",
    "\n",
    "messages.push(aiMessage);\n",
    "\n",
    "const toolsByName = {\n",
    "  add: addTool,\n",
    "  multiply: multiplyTool,\n",
    "}\n",
    "\n",
    "for (const toolCall of aiMessage.tool_calls) {\n",
    "  const selectedTool = toolsByName[toolCall.name];\n",
    "  const toolMessage = await selectedTool.invoke(toolCall);\n",
    "  messages.push(toolMessage);\n",
    "}\n",
    "\n",
    "console.log(messages);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage {\n",
      "  lc_serializable: true,\n",
      "  lc_kwargs: {\n",
      "    content: '3 * 12 is 36, and 11 + 49 is 60.',\n",
      "    tool_calls: [],\n",
      "    invalid_tool_calls: [],\n",
      "    additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "    id: 'chatcmpl-9llB0VVQNdufqhJHHtY9yCPeQeKLZ',\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  lc_namespace: [ 'langchain_core', 'messages' ],\n",
      "  content: '3 * 12 is 36, and 11 + 49 is 60.',\n",
      "  name: undefined,\n",
      "  additional_kwargs: { function_call: undefined, tool_calls: undefined },\n",
      "  response_metadata: {\n",
      "    tokenUsage: { completionTokens: 19, promptTokens: 153, totalTokens: 172 },\n",
      "    finish_reason: 'stop'\n",
      "  },\n",
      "  id: 'chatcmpl-9llB0VVQNdufqhJHHtY9yCPeQeKLZ',\n",
      "  tool_calls: [],\n",
      "  invalid_tool_calls: [],\n",
      "  usage_metadata: { input_tokens: 153, output_tokens: 19, total_tokens: 172 }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "await llmWithTools.invoke(messages);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we pass back the same `tool_call_id` in the `ToolMessage` as what we receive from the model in order to help the model match tool responses with tool calls.\n",
    "\n",
    "## Related\n",
    "\n",
    "You've now seen how to pass tool calls back to a model.\n",
    "\n",
    "These guides may interest you next:\n",
    "\n",
    "- [Creating custom tools](/docs/how_to/custom_tools)\n",
    "- [Building agents with LangGraph](https://langchain-ai.github.io/langgraphjs/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
