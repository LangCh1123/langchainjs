{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579c24a2",
   "metadata": {},
   "source": [
    "# How to migrate from legacy LangChain agents to LangGraph\n",
    "\n",
    "Here we focus on how to move from legacy LangChain agents to LangGraph agents.\n",
    "LangChain agents (the\n",
    "[AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor)\n",
    "in particular) have multiple configuration parameters. In this notebook we will\n",
    "show how those parameters map to the LangGraph\n",
    "[react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent).\n",
    "\n",
    "For more information on how to build agentic workflows in LangGraph, check out\n",
    "the [docs here](https://langchain-ai.github.io/langgraphjs/how-tos/).\n",
    "\n",
    "#### Prerequisites\n",
    "\n",
    "This how-to guide uses Claude (model: \"claude-3-haiku-20240307\") as the LLM. Set\n",
    "your Anthropic API key to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ef582f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "// process.env.ANTHROPIC_API_KEY = \"sk-...\";\n",
    "\n",
    "// Optional, add tracing in LangSmith\n",
    "// process.env.LANGCHAIN_API_KEY = \"ls...\";\n",
    "process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\n",
    "process.env.LANGCHAIN_TRACING_V2 = \"true\";\n",
    "process.env.LANGCHAIN_PROJECT = \"How to migrate: LangGraphJS\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ff5c79",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "For basic creation and usage of a tool-calling ReAct-style agent, the\n",
    "functionality is the same. First, let's define a model and tool(s), then we'll\n",
    "use those to create an agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1222c5e2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import { DynamicStructuredTool } from \"@langchain/core/tools\";\n",
    "import { z } from \"zod\";\n",
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "\n",
    "const llm = new ChatAnthropic({ model: \"claude-3-haiku-20240307\" });\n",
    "\n",
    "const magicTool = new DynamicStructuredTool({\n",
    "  name: \"magic_function\",\n",
    "  description: \"Applies a magic function to an input.\",\n",
    "  schema: z.object({\n",
    "    input: z.number(),\n",
    "  }),\n",
    "  func: async ({ input }: { input: number }) => {\n",
    "    return `${input + 2}`;\n",
    "  },\n",
    "});\n",
    "\n",
    "const tools = [magicTool];\n",
    "\n",
    "const query = \"what is the value of magic_function(3)?\";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768d9e8c",
   "metadata": {},
   "source": [
    "For the LangChain\n",
    "[AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor),\n",
    "we define a prompt with a placeholder for the agent's scratchpad. The agent can\n",
    "be invoked as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e52bf891",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  input: \u001b[32m\"what is the value of magic_function(3)?\"\u001b[39m,\n",
       "  output: \u001b[32m\"So the value of magic_function(3) is 5.\"\u001b[39m\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import {\n",
    "  ChatPromptTemplate,\n",
    "  MessagesPlaceholder,\n",
    "} from \"@langchain/core/prompts\";\n",
    "import { createToolCallingAgent } from \"langchain/agents\";\n",
    "import { AgentExecutor } from \"langchain/agents\";\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", \"You are a helpful assistant\"],\n",
    "  [\"human\", `{input}`],\n",
    "  new MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "]);\n",
    "\n",
    "const agent = createToolCallingAgent({ llm: llm, tools: tools, prompt });\n",
    "const agentExecutor = new AgentExecutor({ agent, tools: tools });\n",
    "\n",
    "await agentExecutor.invoke({ input: query });\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3e5db9",
   "metadata": {},
   "source": [
    "LangGraph's\n",
    "[react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent)\n",
    "manages a state that is defined by a list of messages. It will continue to\n",
    "process the list until there are no tool calls in the agent's output. To kick it\n",
    "off, we input a list of messages. The output will contain the entire state of\n",
    "the graph-- in this case, the conversation history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcda7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const app = createReactAgent({ llm, tools });\n",
    "\n",
    "let agentOutput = await app.invoke({ messages: [new HumanMessage(query)] });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0a390a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  messages: [\n",
       "    HumanMessage {\n",
       "      lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "      lc_kwargs: {\n",
       "        content: \u001b[32m\"what is the value of magic_function(3)?\"\u001b[39m,\n",
       "        additional_kwargs: {},\n",
       "        response_metadata: {}\n",
       "      },\n",
       "      lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "      content: \u001b[32m\"what is the value of magic_function(3)?\"\u001b[39m,\n",
       "      name: \u001b[90mundefined\u001b[39m,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    AIMessage {\n",
       "      lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "      lc_kwargs: {\n",
       "        content: [ \u001b[36m[Object]\u001b[39m, \u001b[36m[Object]\u001b[39m ],\n",
       "        additional_kwargs: {\n",
       "          id: \u001b[32m\"msg_01CykT2w3Wgp4tP4MRET3S8j\"\u001b[39m,\n",
       "          type: \u001b[32m\"message\"\u001b[39m,\n",
       "          role: \u001b[32m\"assistant\"\u001b[39m,\n",
       "          model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "          stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "          usage: \u001b[36m[Object]\u001b[39m,\n",
       "          stop_reason: \u001b[32m\"tool_use\"\u001b[39m\n",
       "        },\n",
       "        tool_calls: [ \u001b[36m[Object]\u001b[39m ],\n",
       "        invalid_tool_calls: [],\n",
       "        response_metadata: {}\n",
       "      },\n",
       "      lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "      content: [\n",
       "        {\n",
       "          type: \u001b[32m\"text\"\u001b[39m,\n",
       "          text: \u001b[32m\"Here is the result of applying the magic_function to the input of 3:\"\u001b[39m\n",
       "        },\n",
       "        {\n",
       "          type: \u001b[32m\"tool_use\"\u001b[39m,\n",
       "          id: \u001b[32m\"toolu_01AFWFmYzVu8MauPY9rQKNCy\"\u001b[39m,\n",
       "          name: \u001b[32m\"magic_function\"\u001b[39m,\n",
       "          input: \u001b[36m[Object]\u001b[39m\n",
       "        }\n",
       "      ],\n",
       "      name: \u001b[90mundefined\u001b[39m,\n",
       "      additional_kwargs: {\n",
       "        id: \u001b[32m\"msg_01CykT2w3Wgp4tP4MRET3S8j\"\u001b[39m,\n",
       "        type: \u001b[32m\"message\"\u001b[39m,\n",
       "        role: \u001b[32m\"assistant\"\u001b[39m,\n",
       "        model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "        stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "        usage: { input_tokens: \u001b[33m365\u001b[39m, output_tokens: \u001b[33m71\u001b[39m },\n",
       "        stop_reason: \u001b[32m\"tool_use\"\u001b[39m\n",
       "      },\n",
       "      response_metadata: {\n",
       "        id: \u001b[32m\"msg_01CykT2w3Wgp4tP4MRET3S8j\"\u001b[39m,\n",
       "        model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "        stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "        usage: { input_tokens: \u001b[33m365\u001b[39m, output_tokens: \u001b[33m71\u001b[39m },\n",
       "        stop_reason: \u001b[32m\"tool_use\"\u001b[39m\n",
       "      },\n",
       "      tool_calls: [\n",
       "        {\n",
       "          name: \u001b[32m\"magic_function\"\u001b[39m,\n",
       "          args: \u001b[36m[Object]\u001b[39m,\n",
       "          id: \u001b[32m\"toolu_01AFWFmYzVu8MauPY9rQKNCy\"\u001b[39m\n",
       "        }\n",
       "      ],\n",
       "      invalid_tool_calls: []\n",
       "    },\n",
       "    ToolMessage {\n",
       "      lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "      lc_kwargs: {\n",
       "        name: \u001b[32m\"magic_function\"\u001b[39m,\n",
       "        content: \u001b[32m\"5\"\u001b[39m,\n",
       "        tool_call_id: \u001b[32m\"toolu_01AFWFmYzVu8MauPY9rQKNCy\"\u001b[39m,\n",
       "        additional_kwargs: {},\n",
       "        response_metadata: {}\n",
       "      },\n",
       "      lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "      content: \u001b[32m\"5\"\u001b[39m,\n",
       "      name: \u001b[32m\"magic_function\"\u001b[39m,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {},\n",
       "      tool_call_id: \u001b[32m\"toolu_01AFWFmYzVu8MauPY9rQKNCy\"\u001b[39m\n",
       "    },\n",
       "    AIMessage {\n",
       "      lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "      lc_kwargs: {\n",
       "        content: \u001b[32m\"The magic_function takes a number as input and returns a value that is 2 greater than the input. So,\"\u001b[39m... 68 more characters,\n",
       "        tool_calls: [],\n",
       "        invalid_tool_calls: [],\n",
       "        additional_kwargs: {\n",
       "          id: \u001b[32m\"msg_01UWZFf2upsHK2jWwMQRjukv\"\u001b[39m,\n",
       "          type: \u001b[32m\"message\"\u001b[39m,\n",
       "          role: \u001b[32m\"assistant\"\u001b[39m,\n",
       "          model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "          stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "          usage: \u001b[36m[Object]\u001b[39m,\n",
       "          stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
       "        },\n",
       "        response_metadata: {}\n",
       "      },\n",
       "      lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "      content: \u001b[32m\"The magic_function takes a number as input and returns a value that is 2 greater than the input. So,\"\u001b[39m... 68 more characters,\n",
       "      name: \u001b[90mundefined\u001b[39m,\n",
       "      additional_kwargs: {\n",
       "        id: \u001b[32m\"msg_01UWZFf2upsHK2jWwMQRjukv\"\u001b[39m,\n",
       "        type: \u001b[32m\"message\"\u001b[39m,\n",
       "        role: \u001b[32m\"assistant\"\u001b[39m,\n",
       "        model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "        stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "        usage: { input_tokens: \u001b[33m448\u001b[39m, output_tokens: \u001b[33m49\u001b[39m },\n",
       "        stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
       "      },\n",
       "      response_metadata: {\n",
       "        id: \u001b[32m\"msg_01UWZFf2upsHK2jWwMQRjukv\"\u001b[39m,\n",
       "        model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "        stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "        usage: { input_tokens: \u001b[33m448\u001b[39m, output_tokens: \u001b[33m49\u001b[39m },\n",
       "        stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
       "      },\n",
       "      tool_calls: [],\n",
       "      invalid_tool_calls: []\n",
       "    },\n",
       "    HumanMessage {\n",
       "      lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "      lc_kwargs: {\n",
       "        content: \u001b[32m\"Pardon?\"\u001b[39m,\n",
       "        additional_kwargs: {},\n",
       "        response_metadata: {}\n",
       "      },\n",
       "      lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "      content: \u001b[32m\"Pardon?\"\u001b[39m,\n",
       "      name: \u001b[90mundefined\u001b[39m,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {}\n",
       "    },\n",
       "    AIMessage {\n",
       "      lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "      lc_kwargs: {\n",
       "        content: [ \u001b[36m[Object]\u001b[39m, \u001b[36m[Object]\u001b[39m ],\n",
       "        additional_kwargs: {\n",
       "          id: \u001b[32m\"msg_01QdxJbZKchtLXPZQpWSua3u\"\u001b[39m,\n",
       "          type: \u001b[32m\"message\"\u001b[39m,\n",
       "          role: \u001b[32m\"assistant\"\u001b[39m,\n",
       "          model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "          stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "          usage: \u001b[36m[Object]\u001b[39m,\n",
       "          stop_reason: \u001b[32m\"tool_use\"\u001b[39m\n",
       "        },\n",
       "        tool_calls: [ \u001b[36m[Object]\u001b[39m ],\n",
       "        invalid_tool_calls: [],\n",
       "        response_metadata: {}\n",
       "      },\n",
       "      lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "      content: [\n",
       "        {\n",
       "          type: \u001b[32m\"text\"\u001b[39m,\n",
       "          text: \u001b[32m\"I apologize for the confusion. Let me explain the magic_function in more detail:\\n\"\u001b[39m +\n",
       "            \u001b[32m\"\\n\"\u001b[39m +\n",
       "            \u001b[32m\"The magic_function\"\u001b[39m... 128 more characters\n",
       "        },\n",
       "        {\n",
       "          type: \u001b[32m\"tool_use\"\u001b[39m,\n",
       "          id: \u001b[32m\"toolu_01CsCyHEKTpsnafjUkhebZDm\"\u001b[39m,\n",
       "          name: \u001b[32m\"magic_function\"\u001b[39m,\n",
       "          input: \u001b[36m[Object]\u001b[39m\n",
       "        }\n",
       "      ],\n",
       "      name: \u001b[90mundefined\u001b[39m,\n",
       "      additional_kwargs: {\n",
       "        id: \u001b[32m\"msg_01QdxJbZKchtLXPZQpWSua3u\"\u001b[39m,\n",
       "        type: \u001b[32m\"message\"\u001b[39m,\n",
       "        role: \u001b[32m\"assistant\"\u001b[39m,\n",
       "        model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "        stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "        usage: { input_tokens: \u001b[33m504\u001b[39m, output_tokens: \u001b[33m109\u001b[39m },\n",
       "        stop_reason: \u001b[32m\"tool_use\"\u001b[39m\n",
       "      },\n",
       "      response_metadata: {\n",
       "        id: \u001b[32m\"msg_01QdxJbZKchtLXPZQpWSua3u\"\u001b[39m,\n",
       "        model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "        stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "        usage: { input_tokens: \u001b[33m504\u001b[39m, output_tokens: \u001b[33m109\u001b[39m },\n",
       "        stop_reason: \u001b[32m\"tool_use\"\u001b[39m\n",
       "      },\n",
       "      tool_calls: [\n",
       "        {\n",
       "          name: \u001b[32m\"magic_function\"\u001b[39m,\n",
       "          args: \u001b[36m[Object]\u001b[39m,\n",
       "          id: \u001b[32m\"toolu_01CsCyHEKTpsnafjUkhebZDm\"\u001b[39m\n",
       "        }\n",
       "      ],\n",
       "      invalid_tool_calls: []\n",
       "    },\n",
       "    ToolMessage {\n",
       "      lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "      lc_kwargs: {\n",
       "        name: \u001b[32m\"magic_function\"\u001b[39m,\n",
       "        content: \u001b[32m\"5\"\u001b[39m,\n",
       "        tool_call_id: \u001b[32m\"toolu_01CsCyHEKTpsnafjUkhebZDm\"\u001b[39m,\n",
       "        additional_kwargs: {},\n",
       "        response_metadata: {}\n",
       "      },\n",
       "      lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "      content: \u001b[32m\"5\"\u001b[39m,\n",
       "      name: \u001b[32m\"magic_function\"\u001b[39m,\n",
       "      additional_kwargs: {},\n",
       "      response_metadata: {},\n",
       "      tool_call_id: \u001b[32m\"toolu_01CsCyHEKTpsnafjUkhebZDm\"\u001b[39m\n",
       "    },\n",
       "    AIMessage {\n",
       "      lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "      lc_kwargs: {\n",
       "        content: \u001b[32m\"The input value of 3 is passed to the magic_function, and the function returns the value of 5, which\"\u001b[39m... 109 more characters,\n",
       "        tool_calls: [],\n",
       "        invalid_tool_calls: [],\n",
       "        additional_kwargs: {\n",
       "          id: \u001b[32m\"msg_01VBTdCFhE6fxysiyuiSyW6Z\"\u001b[39m,\n",
       "          type: \u001b[32m\"message\"\u001b[39m,\n",
       "          role: \u001b[32m\"assistant\"\u001b[39m,\n",
       "          model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "          stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "          usage: \u001b[36m[Object]\u001b[39m,\n",
       "          stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
       "        },\n",
       "        response_metadata: {}\n",
       "      },\n",
       "      lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "      content: \u001b[32m\"The input value of 3 is passed to the magic_function, and the function returns the value of 5, which\"\u001b[39m... 109 more characters,\n",
       "      name: \u001b[90mundefined\u001b[39m,\n",
       "      additional_kwargs: {\n",
       "        id: \u001b[32m\"msg_01VBTdCFhE6fxysiyuiSyW6Z\"\u001b[39m,\n",
       "        type: \u001b[32m\"message\"\u001b[39m,\n",
       "        role: \u001b[32m\"assistant\"\u001b[39m,\n",
       "        model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "        stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "        usage: { input_tokens: \u001b[33m625\u001b[39m, output_tokens: \u001b[33m59\u001b[39m },\n",
       "        stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
       "      },\n",
       "      response_metadata: {\n",
       "        id: \u001b[32m\"msg_01VBTdCFhE6fxysiyuiSyW6Z\"\u001b[39m,\n",
       "        model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "        stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "        usage: { input_tokens: \u001b[33m625\u001b[39m, output_tokens: \u001b[33m59\u001b[39m },\n",
       "        stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
       "      },\n",
       "      tool_calls: [],\n",
       "      invalid_tool_calls: []\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const messageHistory = agentOutput.messages;\n",
    "const newQuery = \"Pardon?\";\n",
    "\n",
    "agentOutput = await app.invoke({\n",
    "  messages: [...messageHistory, new HumanMessage(newQuery)],\n",
    "});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a12f7a",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "\n",
    "With legacy LangChain agents you have to pass in a prompt template. You can use\n",
    "this to control the agent.\n",
    "\n",
    "With LangGraph\n",
    "[react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent),\n",
    "by default there is no prompt. You can achieve similar control over the agent in\n",
    "a few ways:\n",
    "\n",
    "1. Pass in a system message as input\n",
    "2. Initialize the agent with a system message\n",
    "3. Initialize the agent with a function to transform messages before passing to\n",
    "   the model.\n",
    "\n",
    "Let's take a look at all of these below. We will pass in custom instructions to\n",
    "get the agent to respond in Spanish.\n",
    "\n",
    "First up, using AgentExecutor:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c5266cc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  input: \u001b[32m\"what is the value of magic_function(3)?\"\u001b[39m,\n",
       "  output: \u001b[32m\"Por lo tanto, el resultado de aplicar la función mágica al valor 3 es 5.\"\u001b[39m\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const spanishPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", \"You are a helpful assistant. Respond only in Spanish.\"],\n",
    "  [\"human\", `{input}`],\n",
    "  new MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "]);\n",
    "\n",
    "const spanishAgent = createToolCallingAgent({\n",
    "  llm: llm,\n",
    "  tools: tools,\n",
    "  prompt: spanishPrompt,\n",
    "});\n",
    "const spanishAgentExecutor = new AgentExecutor({\n",
    "  agent: spanishAgent,\n",
    "  tools: tools,\n",
    "});\n",
    "\n",
    "await spanishAgentExecutor.invoke({ input: query });\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54b374d",
   "metadata": {},
   "source": [
    "Now, let's pass a custom system message to\n",
    "[react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent).\n",
    "This can either be a string or a LangChain SystemMessage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38a751ba",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "  lc_kwargs: {\n",
       "    content: \u001b[32m\"El valor de invocar magic_function(3) es 5.\"\u001b[39m,\n",
       "    tool_calls: [],\n",
       "    invalid_tool_calls: [],\n",
       "    additional_kwargs: {\n",
       "      id: \u001b[32m\"msg_01Tjm4DqarRZLakrxHBEpXF4\"\u001b[39m,\n",
       "      type: \u001b[32m\"message\"\u001b[39m,\n",
       "      role: \u001b[32m\"assistant\"\u001b[39m,\n",
       "      model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "      stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "      usage: { input_tokens: \u001b[33m444\u001b[39m, output_tokens: \u001b[33m19\u001b[39m },\n",
       "      stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
       "    },\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "  content: \u001b[32m\"El valor de invocar magic_function(3) es 5.\"\u001b[39m,\n",
       "  name: \u001b[90mundefined\u001b[39m,\n",
       "  additional_kwargs: {\n",
       "    id: \u001b[32m\"msg_01Tjm4DqarRZLakrxHBEpXF4\"\u001b[39m,\n",
       "    type: \u001b[32m\"message\"\u001b[39m,\n",
       "    role: \u001b[32m\"assistant\"\u001b[39m,\n",
       "    model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "    stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "    usage: { input_tokens: \u001b[33m444\u001b[39m, output_tokens: \u001b[33m19\u001b[39m },\n",
       "    stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
       "  },\n",
       "  response_metadata: {\n",
       "    id: \u001b[32m\"msg_01Tjm4DqarRZLakrxHBEpXF4\"\u001b[39m,\n",
       "    model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
       "    stop_sequence: \u001b[1mnull\u001b[22m,\n",
       "    usage: { input_tokens: \u001b[33m444\u001b[39m, output_tokens: \u001b[33m19\u001b[39m },\n",
       "    stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
       "  },\n",
       "  tool_calls: [],\n",
       "  invalid_tool_calls: []\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { SystemMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const systemMessage = \"You are a helpful assistant. Respond only in Spanish.\";\n",
    "\n",
    "// This could also be a SystemMessage object\n",
    "// const systemMessage = new SystemMessage(\"You are a helpful assistant. Respond only in Spanish.\");\n",
    "\n",
    "const appWithSystemMessage = createReactAgent({\n",
    "  llm,\n",
    "  tools,\n",
    "  messageModifier: systemMessage,\n",
    "});\n",
    "\n",
    "agentOutput = await appWithSystemMessage.invoke({\n",
    "  messages: [new HumanMessage(query)],\n",
    "});\n",
    "agentOutput.messages[agentOutput.messages.length - 1];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7622d8f7",
   "metadata": {},
   "source": [
    "We can also pass in an arbitrary function. This function should take in a list\n",
    "of messages and output a list of messages. We can do all types of arbitrary\n",
    "formatting of messages here. In this cases, let's just add a SystemMessage to\n",
    "the start of the list of messages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7120cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  input: \u001b[32m\"what is the value of magic_function(3)?\"\u001b[39m,\n",
      "  output: \u001b[32m\"5. ¡Pandamonium!\"\u001b[39m\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { BaseMessage, SystemMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const modifyMessages = (messages: BaseMessage[]) => {\n",
    "  return [\n",
    "    new SystemMessage(\"You are a helpful assistant. Respond only in Spanish.\"),\n",
    "    ...messages,\n",
    "    new HumanMessage(\"Also say 'Pandamonium!' after the answer.\"),\n",
    "  ];\n",
    "};\n",
    "\n",
    "const appWithMessagesModifier = createReactAgent({\n",
    "  llm,\n",
    "  tools,\n",
    "  messageModifier: modifyMessages,\n",
    "});\n",
    "\n",
    "agentOutput = await appWithMessagesModifier.invoke({\n",
    "  messages: [new HumanMessage(query)],\n",
    "});\n",
    "\n",
    "console.log({\n",
    "  input: query,\n",
    "  output: agentOutput.messages[agentOutput.messages.length - 1].content,\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44337a14",
   "metadata": {},
   "source": [
    "## Memory\n",
    "\n",
    "With LangChain's\n",
    "[AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter),\n",
    "you could add chat\n",
    "[Memory](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.memory)\n",
    "so it can engage in a multi-turn conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d67ba36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The magic_function applied to the input of 3 outputs the value 5.\n",
      "---\n",
      "I'm afraid I don't actually have the capability to remember your name. As an AI assistant, I don't have a persistent memory of our conversation or personal details about you. I respond based on the current context of our interaction. Could you please restate your request so I can try to assist you further?\n",
      "---\n",
      "I don't have any previous output to reference. Could you please provide more context about what you are asking about? I'd be happy to assist once I understand the specific request you have.\n"
     ]
    }
   ],
   "source": [
    "import { ChatMessageHistory } from \"@langchain/community/stores/message/in_memory\";\n",
    "import { RunnableWithMessageHistory } from \"@langchain/core/runnables\";\n",
    "\n",
    "const memory = new ChatMessageHistory();\n",
    "const agentExecutorWithMemory = new RunnableWithMessageHistory({\n",
    "  runnable: agentExecutor,\n",
    "  getMessageHistory: () => memory,\n",
    "  inputMessagesKey: \"input\",\n",
    "  historyMessagesKey: \"chat_history\",\n",
    "});\n",
    "\n",
    "const config = { configurable: { sessionId: \"test-session\" } };\n",
    "\n",
    "agentOutput = await agentExecutorWithMemory.invoke(\n",
    "  { input: \"Hi, I'm polly! What's the output of magic_function of 3?\" },\n",
    "  config,\n",
    ");\n",
    "console.log(agentOutput.output);\n",
    "agentOutput = await agentExecutorWithMemory.invoke(\n",
    "  { input: \"Remember my name?\" },\n",
    "  config,\n",
    ");\n",
    "console.log(\"---\");\n",
    "console.log(agentOutput.output);\n",
    "console.log(\"---\");\n",
    "agentOutput = await agentExecutorWithMemory.invoke(\n",
    "  { input: \"what was that output again?\" },\n",
    "  config,\n",
    ");\n",
    "console.log(agentOutput.output);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe4e21",
   "metadata": {},
   "source": [
    "#### In LangGraph\n",
    "\n",
    "Memory is just\n",
    "[persistence](https://langchain-ai.github.io/langgraph/how-tos/persistence/),\n",
    "aka\n",
    "[checkpointing](https://langchain-ai.github.io/langgraph/reference/checkpoints/).\n",
    "\n",
    "Add a `checkpointer` to the agent and you get chat memory for free.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbc64438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The magic_function applied to the input of 3 returns the output of 5.\n",
      "---\n",
      "It's nice to meet you, Polly! I'll be sure to remember your name.\n",
      "---\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import { MemorySaver } from \"@langchain/langgraph\";\n",
    "\n",
    "const memory = new MemorySaver();\n",
    "const appWithMemory = createReactAgent({ llm, tools, checkpointSaver: memory });\n",
    "\n",
    "const config = { configurable: { thread_id: \"test-thread\" } };\n",
    "\n",
    "agentOutput = await appWithMemory.invoke(\n",
    "  {\n",
    "    messages: [\n",
    "      new HumanMessage(\n",
    "        \"Hi, I'm polly! What's the output of magic_function of 3?\",\n",
    "      ),\n",
    "    ],\n",
    "  },\n",
    "  config,\n",
    ");\n",
    "console.log(agentOutput.messages[agentOutput.messages.length - 1].content);\n",
    "console.log(\"---\");\n",
    "agentOutput = await appWithMemory.invoke(\n",
    "  { messages: [new HumanMessage(\"Remember my name?\")] },\n",
    "  config,\n",
    ");\n",
    "console.log(agentOutput.messages[agentOutput.messages.length - 1].content);\n",
    "console.log(\"---\");\n",
    "agentOutput = await appWithMemory.invoke(\n",
    "  { messages: [new HumanMessage(\"what was that output again?\")] },\n",
    "  config,\n",
    ");\n",
    "console.log(agentOutput.messages[agentOutput.messages.length - 1].content);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2997b4da",
   "metadata": {},
   "source": [
    "## Iterating through steps\n",
    "\n",
    "With LangChain's\n",
    "[AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter),\n",
    "you could iterate over the steps using the\n",
    "[stream](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream)\n",
    "(or async `astream`) methods or the\n",
    "[iter](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter)\n",
    "method. LangGraph supports stepwise iteration using\n",
    "[stream](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c928049",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  intermediateSteps: [\n",
      "    {\n",
      "      action: {\n",
      "        tool: \u001b[32m\"magic_function\"\u001b[39m,\n",
      "        toolInput: { input: \u001b[33m3\u001b[39m },\n",
      "        toolCallId: \u001b[32m\"toolu_01FXcVYzTS9NH9urhUcL3jmw\"\u001b[39m,\n",
      "        log: \u001b[32m'Invoking \"magic_function\" with {\"input\":3}\\n'\u001b[39m +\n",
      "          \u001b[32m`[{\"type\":\"text\",\"text\":\"Okay, let's use the magic_functio`\u001b[39m... 156 more characters,\n",
      "        messageLog: [ \u001b[36m[AIMessageChunk]\u001b[39m ]\n",
      "      },\n",
      "      observation: \u001b[32m\"5\"\u001b[39m\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  output: \u001b[32m\"The magic_function tool takes an input number and returns a transformed value. When we call magic_fu\"\u001b[39m... 34 more characters\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for await (const step of await agentExecutor.stream({ input: query })) {\n",
    "  console.log(step);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd371818",
   "metadata": {},
   "source": [
    "#### In LangGraph\n",
    "\n",
    "In LangGraph, things are handled natively using\n",
    "[stream](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.graph.CompiledGraph.stream)\n",
    "or the asynchronous `astream` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2be89a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  agent: {\n",
      "    messages: [\n",
      "      AIMessage {\n",
      "        lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "        lc_kwargs: {\n",
      "          content: \u001b[36m[Array]\u001b[39m,\n",
      "          additional_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          tool_calls: \u001b[36m[Array]\u001b[39m,\n",
      "          invalid_tool_calls: [],\n",
      "          response_metadata: {}\n",
      "        },\n",
      "        lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "        content: [ \u001b[36m[Object]\u001b[39m, \u001b[36m[Object]\u001b[39m ],\n",
      "        name: \u001b[90mundefined\u001b[39m,\n",
      "        additional_kwargs: {\n",
      "          id: \u001b[32m\"msg_01CYJghzEr6kx35rWfHc8PMo\"\u001b[39m,\n",
      "          type: \u001b[32m\"message\"\u001b[39m,\n",
      "          role: \u001b[32m\"assistant\"\u001b[39m,\n",
      "          model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
      "          stop_sequence: \u001b[1mnull\u001b[22m,\n",
      "          usage: \u001b[36m[Object]\u001b[39m,\n",
      "          stop_reason: \u001b[32m\"tool_use\"\u001b[39m\n",
      "        },\n",
      "        response_metadata: {\n",
      "          id: \u001b[32m\"msg_01CYJghzEr6kx35rWfHc8PMo\"\u001b[39m,\n",
      "          model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
      "          stop_sequence: \u001b[1mnull\u001b[22m,\n",
      "          usage: \u001b[36m[Object]\u001b[39m,\n",
      "          stop_reason: \u001b[32m\"tool_use\"\u001b[39m\n",
      "        },\n",
      "        tool_calls: [ \u001b[36m[Object]\u001b[39m ],\n",
      "        invalid_tool_calls: []\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "{\n",
      "  tools: {\n",
      "    messages: [\n",
      "      ToolMessage {\n",
      "        lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "        lc_kwargs: {\n",
      "          name: \u001b[32m\"magic_function\"\u001b[39m,\n",
      "          content: \u001b[32m\"5\"\u001b[39m,\n",
      "          tool_call_id: \u001b[32m\"toolu_0113AWaBai9Mr4rSE9VFQkUD\"\u001b[39m,\n",
      "          additional_kwargs: {},\n",
      "          response_metadata: {}\n",
      "        },\n",
      "        lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "        content: \u001b[32m\"5\"\u001b[39m,\n",
      "        name: \u001b[32m\"magic_function\"\u001b[39m,\n",
      "        additional_kwargs: {},\n",
      "        response_metadata: {},\n",
      "        tool_call_id: \u001b[32m\"toolu_0113AWaBai9Mr4rSE9VFQkUD\"\u001b[39m\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "{\n",
      "  agent: {\n",
      "    messages: [\n",
      "      AIMessage {\n",
      "        lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "        lc_kwargs: {\n",
      "          content: \u001b[32m\"The magic_function takes an input number and returns a value 2 higher than the input. So magic_funct\"\u001b[39m... 17 more characters,\n",
      "          tool_calls: [],\n",
      "          invalid_tool_calls: [],\n",
      "          additional_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          response_metadata: {}\n",
      "        },\n",
      "        lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "        content: \u001b[32m\"The magic_function takes an input number and returns a value 2 higher than the input. So magic_funct\"\u001b[39m... 17 more characters,\n",
      "        name: \u001b[90mundefined\u001b[39m,\n",
      "        additional_kwargs: {\n",
      "          id: \u001b[32m\"msg_0131seN8QkQaDxQC46MmiVfd\"\u001b[39m,\n",
      "          type: \u001b[32m\"message\"\u001b[39m,\n",
      "          role: \u001b[32m\"assistant\"\u001b[39m,\n",
      "          model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
      "          stop_sequence: \u001b[1mnull\u001b[22m,\n",
      "          usage: \u001b[36m[Object]\u001b[39m,\n",
      "          stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
      "        },\n",
      "        response_metadata: {\n",
      "          id: \u001b[32m\"msg_0131seN8QkQaDxQC46MmiVfd\"\u001b[39m,\n",
      "          model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
      "          stop_sequence: \u001b[1mnull\u001b[22m,\n",
      "          usage: \u001b[36m[Object]\u001b[39m,\n",
      "          stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
      "        },\n",
      "        tool_calls: [],\n",
      "        invalid_tool_calls: []\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for await (\n",
    "  const step of await app.stream(\n",
    "    { messages: [new HumanMessage(query)] },\n",
    "    { streamMode: \"updates\" },\n",
    "  )\n",
    ") {\n",
    "  console.log(step);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce023792",
   "metadata": {},
   "source": [
    "## `return_intermediate_steps`\n",
    "\n",
    "Setting this parameter on AgentExecutor allows users to access\n",
    "intermediate_steps, which pairs agent actions (e.g., tool invocations) with\n",
    "their outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77ce2771",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    action: {\n",
      "      tool: \u001b[32m\"magic_function\"\u001b[39m,\n",
      "      toolInput: { input: \u001b[33m3\u001b[39m },\n",
      "      toolCallId: \u001b[32m\"toolu_017Q69gSfYvkXSNus9mU8wrL\"\u001b[39m,\n",
      "      log: \u001b[32m'Invoking \"magic_function\" with {\"input\":3}\\n'\u001b[39m +\n",
      "        \u001b[32m`[{\"type\":\"text\",\"text\":\"Okay, let's use the magic_functio`\u001b[39m... 151 more characters,\n",
      "      messageLog: [\n",
      "        AIMessageChunk {\n",
      "          lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "          lc_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          lc_namespace: \u001b[36m[Array]\u001b[39m,\n",
      "          content: \u001b[36m[Array]\u001b[39m,\n",
      "          name: \u001b[90mundefined\u001b[39m,\n",
      "          additional_kwargs: \u001b[36m[Object]\u001b[39m,\n",
      "          response_metadata: {},\n",
      "          tool_calls: \u001b[36m[Array]\u001b[39m,\n",
      "          invalid_tool_calls: [],\n",
      "          tool_call_chunks: \u001b[36m[Array]\u001b[39m\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    observation: \u001b[32m\"5\"\u001b[39m\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "const agentExecutorWithIntermediateSteps = new AgentExecutor({\n",
    "  agent: agent,\n",
    "  tools: tools,\n",
    "  returnIntermediateSteps: true,\n",
    "});\n",
    "\n",
    "const result = await agentExecutorWithIntermediateSteps.invoke({\n",
    "  input: query,\n",
    "});\n",
    "\n",
    "console.log(result.intermediateSteps);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050845ae",
   "metadata": {},
   "source": [
    "By default the\n",
    "[react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent)\n",
    "in LangGraph appends all messages to the central state. Therefore, it is easy to\n",
    "see any intermediate steps by just looking at the full state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f9cdfa8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  HumanMessage {\n",
      "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "    lc_kwargs: {\n",
      "      content: \u001b[32m\"what is the value of magic_function(3)?\"\u001b[39m,\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "    content: \u001b[32m\"what is the value of magic_function(3)?\"\u001b[39m,\n",
      "    name: \u001b[90mundefined\u001b[39m,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  AIMessage {\n",
      "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "    lc_kwargs: {\n",
      "      content: [\n",
      "        {\n",
      "          type: \u001b[32m\"text\"\u001b[39m,\n",
      "          text: \u001b[32m\"Here is the result of calling the magic_function with an input of 3:\"\u001b[39m\n",
      "        },\n",
      "        {\n",
      "          type: \u001b[32m\"tool_use\"\u001b[39m,\n",
      "          id: \u001b[32m\"toolu_01VWunWMK2tDtUpeaBhi9qfY\"\u001b[39m,\n",
      "          name: \u001b[32m\"magic_function\"\u001b[39m,\n",
      "          input: \u001b[36m[Object]\u001b[39m\n",
      "        }\n",
      "      ],\n",
      "      additional_kwargs: {\n",
      "        id: \u001b[32m\"msg_01ApEdDDyr54PsqZvzYy6Mhv\"\u001b[39m,\n",
      "        type: \u001b[32m\"message\"\u001b[39m,\n",
      "        role: \u001b[32m\"assistant\"\u001b[39m,\n",
      "        model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
      "        stop_sequence: \u001b[1mnull\u001b[22m,\n",
      "        usage: { input_tokens: \u001b[33m365\u001b[39m, output_tokens: \u001b[33m71\u001b[39m },\n",
      "        stop_reason: \u001b[32m\"tool_use\"\u001b[39m\n",
      "      },\n",
      "      tool_calls: [\n",
      "        {\n",
      "          name: \u001b[32m\"magic_function\"\u001b[39m,\n",
      "          args: \u001b[36m[Object]\u001b[39m,\n",
      "          id: \u001b[32m\"toolu_01VWunWMK2tDtUpeaBhi9qfY\"\u001b[39m\n",
      "        }\n",
      "      ],\n",
      "      invalid_tool_calls: [],\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "    content: [\n",
      "      {\n",
      "        type: \u001b[32m\"text\"\u001b[39m,\n",
      "        text: \u001b[32m\"Here is the result of calling the magic_function with an input of 3:\"\u001b[39m\n",
      "      },\n",
      "      {\n",
      "        type: \u001b[32m\"tool_use\"\u001b[39m,\n",
      "        id: \u001b[32m\"toolu_01VWunWMK2tDtUpeaBhi9qfY\"\u001b[39m,\n",
      "        name: \u001b[32m\"magic_function\"\u001b[39m,\n",
      "        input: { input: \u001b[33m3\u001b[39m }\n",
      "      }\n",
      "    ],\n",
      "    name: \u001b[90mundefined\u001b[39m,\n",
      "    additional_kwargs: {\n",
      "      id: \u001b[32m\"msg_01ApEdDDyr54PsqZvzYy6Mhv\"\u001b[39m,\n",
      "      type: \u001b[32m\"message\"\u001b[39m,\n",
      "      role: \u001b[32m\"assistant\"\u001b[39m,\n",
      "      model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
      "      stop_sequence: \u001b[1mnull\u001b[22m,\n",
      "      usage: { input_tokens: \u001b[33m365\u001b[39m, output_tokens: \u001b[33m71\u001b[39m },\n",
      "      stop_reason: \u001b[32m\"tool_use\"\u001b[39m\n",
      "    },\n",
      "    response_metadata: {\n",
      "      id: \u001b[32m\"msg_01ApEdDDyr54PsqZvzYy6Mhv\"\u001b[39m,\n",
      "      model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
      "      stop_sequence: \u001b[1mnull\u001b[22m,\n",
      "      usage: { input_tokens: \u001b[33m365\u001b[39m, output_tokens: \u001b[33m71\u001b[39m },\n",
      "      stop_reason: \u001b[32m\"tool_use\"\u001b[39m\n",
      "    },\n",
      "    tool_calls: [\n",
      "      {\n",
      "        name: \u001b[32m\"magic_function\"\u001b[39m,\n",
      "        args: { input: \u001b[33m3\u001b[39m },\n",
      "        id: \u001b[32m\"toolu_01VWunWMK2tDtUpeaBhi9qfY\"\u001b[39m\n",
      "      }\n",
      "    ],\n",
      "    invalid_tool_calls: []\n",
      "  },\n",
      "  ToolMessage {\n",
      "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "    lc_kwargs: {\n",
      "      name: \u001b[32m\"magic_function\"\u001b[39m,\n",
      "      content: \u001b[32m\"5\"\u001b[39m,\n",
      "      tool_call_id: \u001b[32m\"toolu_01VWunWMK2tDtUpeaBhi9qfY\"\u001b[39m,\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "    content: \u001b[32m\"5\"\u001b[39m,\n",
      "    name: \u001b[32m\"magic_function\"\u001b[39m,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {},\n",
      "    tool_call_id: \u001b[32m\"toolu_01VWunWMK2tDtUpeaBhi9qfY\"\u001b[39m\n",
      "  },\n",
      "  AIMessage {\n",
      "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
      "    lc_kwargs: {\n",
      "      content: \u001b[32m\"The magic_function takes a number as input and returns a result. When called with an input of 3, the\"\u001b[39m... 30 more characters,\n",
      "      tool_calls: [],\n",
      "      invalid_tool_calls: [],\n",
      "      additional_kwargs: {\n",
      "        id: \u001b[32m\"msg_01AJ5foM2hgpWQr9VGFrPmDa\"\u001b[39m,\n",
      "        type: \u001b[32m\"message\"\u001b[39m,\n",
      "        role: \u001b[32m\"assistant\"\u001b[39m,\n",
      "        model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
      "        stop_sequence: \u001b[1mnull\u001b[22m,\n",
      "        usage: { input_tokens: \u001b[33m448\u001b[39m, output_tokens: \u001b[33m35\u001b[39m },\n",
      "        stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
      "      },\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
      "    content: \u001b[32m\"The magic_function takes a number as input and returns a result. When called with an input of 3, the\"\u001b[39m... 30 more characters,\n",
      "    name: \u001b[90mundefined\u001b[39m,\n",
      "    additional_kwargs: {\n",
      "      id: \u001b[32m\"msg_01AJ5foM2hgpWQr9VGFrPmDa\"\u001b[39m,\n",
      "      type: \u001b[32m\"message\"\u001b[39m,\n",
      "      role: \u001b[32m\"assistant\"\u001b[39m,\n",
      "      model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
      "      stop_sequence: \u001b[1mnull\u001b[22m,\n",
      "      usage: { input_tokens: \u001b[33m448\u001b[39m, output_tokens: \u001b[33m35\u001b[39m },\n",
      "      stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
      "    },\n",
      "    response_metadata: {\n",
      "      id: \u001b[32m\"msg_01AJ5foM2hgpWQr9VGFrPmDa\"\u001b[39m,\n",
      "      model: \u001b[32m\"claude-3-haiku-20240307\"\u001b[39m,\n",
      "      stop_sequence: \u001b[1mnull\u001b[22m,\n",
      "      usage: { input_tokens: \u001b[33m448\u001b[39m, output_tokens: \u001b[33m35\u001b[39m },\n",
      "      stop_reason: \u001b[32m\"end_turn\"\u001b[39m\n",
      "    },\n",
      "    tool_calls: [],\n",
      "    invalid_tool_calls: []\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "agentOutput = await app.invoke({ messages: [new HumanMessage(query)] });\n",
    "\n",
    "console.log(agentOutput.messages);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e671e6",
   "metadata": {},
   "source": [
    "## `max_iterations`\n",
    "\n",
    "`AgentExecutor` implements a `max_iterations` parameter, whereas this is\n",
    "controlled via `recursion_limit` in LangGraph.\n",
    "\n",
    "Note that in AgentExecutor, an \"iteration\" includes a full turn of tool\n",
    "invocation and execution. In LangGraph, each step contributes to the recursion\n",
    "limit, so we will need to multiply by two (and add one) to get equivalent\n",
    "results.\n",
    "\n",
    "If the recursion limit is reached, LangGraph raises a specific exception type,\n",
    "that we can catch and manage similarly to AgentExecutor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cca9d11",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:AgentExecutor\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"what is the value of magic_function(3)?\"\n",
      "}\n",
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m2:chain:ToolCallingAgent\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"what is the value of magic_function(3)?\",\n",
      "  \"steps\": []\n",
      "}\n",
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:ToolCallingAgent > \u001b[1m3:chain:RunnableAssign\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:ToolCallingAgent > 3:chain:RunnableAssign > \u001b[1m4:chain:RunnableMap\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:ToolCallingAgent > 3:chain:RunnableAssign > 4:chain:RunnableMap > \u001b[1m5:chain:RunnableLambda\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:ToolCallingAgent > 3:chain:RunnableAssign > 4:chain:RunnableMap > \u001b[1m5:chain:RunnableLambda\u001b[22m\u001b[39m] [0ms] Exiting Chain run with output: {\n",
      "  \"output\": []\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:ToolCallingAgent > 3:chain:RunnableAssign > \u001b[1m4:chain:RunnableMap\u001b[22m\u001b[39m] [0ms] Exiting Chain run with output: {\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:ToolCallingAgent > \u001b[1m3:chain:RunnableAssign\u001b[22m\u001b[39m] [1ms] Exiting Chain run with output: {\n",
      "  \"input\": \"what is the value of magic_function(3)?\",\n",
      "  \"steps\": [],\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:ToolCallingAgent > \u001b[1m6:prompt:ChatPromptTemplate\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"what is the value of magic_function(3)?\",\n",
      "  \"steps\": [],\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:ToolCallingAgent > \u001b[1m6:prompt:ChatPromptTemplate\u001b[22m\u001b[39m] [1ms] Exiting Chain run with output: {\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain_core\",\n",
      "    \"prompt_values\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"SystemMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are a helpful assistant. Respond only in Spanish.\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"what is the value of magic_function(3)?\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:ToolCallingAgent > \u001b[1m7:llm:ChatAnthropic\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"SystemMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are a helpful assistant. Respond only in Spanish.\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"what is the value of magic_function(3)?\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:ToolCallingAgent > \u001b[1m7:llm:ChatAnthropic\u001b[22m\u001b[39m] [1.12s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Lo siento, pero la herramienta \\\"magic_function\\\" espera un parámetro de tipo \\\"string\\\", no un número entero como \\\"3\\\". Por favor, proporcione una entrada de tipo cadena de texto para poder aplicar la función mágica.\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessageChunk\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Lo siento, pero la herramienta \\\"magic_function\\\" espera un parámetro de tipo \\\"string\\\", no un número entero como \\\"3\\\". Por favor, proporcione una entrada de tipo cadena de texto para poder aplicar la función mágica.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"id\": \"msg_013xWrfNdK1yrTrBg5WVD329\",\n",
      "              \"type\": \"message\",\n",
      "              \"role\": \"assistant\",\n",
      "              \"model\": \"claude-3-haiku-20240307\",\n",
      "              \"stop_sequence\": null,\n",
      "              \"usage\": {\n",
      "                \"input_tokens\": 378,\n",
      "                \"output_tokens\": 63\n",
      "              },\n",
      "              \"stop_reason\": \"end_turn\"\n",
      "            },\n",
      "            \"tool_call_chunks\": [],\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"response_metadata\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:ToolCallingAgent > \u001b[1m8:parser:ToolCallingAgentOutputParser\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain_core\",\n",
      "    \"messages\",\n",
      "    \"AIMessageChunk\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"content\": \"Lo siento, pero la herramienta \\\"magic_function\\\" espera un parámetro de tipo \\\"string\\\", no un número entero como \\\"3\\\". Por favor, proporcione una entrada de tipo cadena de texto para poder aplicar la función mágica.\",\n",
      "    \"additional_kwargs\": {\n",
      "      \"id\": \"msg_013xWrfNdK1yrTrBg5WVD329\",\n",
      "      \"type\": \"message\",\n",
      "      \"role\": \"assistant\",\n",
      "      \"model\": \"claude-3-haiku-20240307\",\n",
      "      \"stop_sequence\": null,\n",
      "      \"usage\": {\n",
      "        \"input_tokens\": 378,\n",
      "        \"output_tokens\": 63\n",
      "      },\n",
      "      \"stop_reason\": \"end_turn\"\n",
      "    },\n",
      "    \"tool_call_chunks\": [],\n",
      "    \"tool_calls\": [],\n",
      "    \"invalid_tool_calls\": [],\n",
      "    \"response_metadata\": {}\n",
      "  }\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > 2:chain:ToolCallingAgent > \u001b[1m8:parser:ToolCallingAgentOutputParser\u001b[22m\u001b[39m] [0ms] Exiting Chain run with output: {\n",
      "  \"returnValues\": {\n",
      "    \"output\": \"Lo siento, pero la herramienta \\\"magic_function\\\" espera un parámetro de tipo \\\"string\\\", no un número entero como \\\"3\\\". Por favor, proporcione una entrada de tipo cadena de texto para poder aplicar la función mágica.\"\n",
      "  },\n",
      "  \"log\": \"Lo siento, pero la herramienta \\\"magic_function\\\" espera un parámetro de tipo \\\"string\\\", no un número entero como \\\"3\\\". Por favor, proporcione una entrada de tipo cadena de texto para poder aplicar la función mágica.\"\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m1:chain:AgentExecutor > \u001b[1m2:chain:ToolCallingAgent\u001b[22m\u001b[39m] [1.12s] Exiting Chain run with output: {\n",
      "  \"returnValues\": {\n",
      "    \"output\": \"Lo siento, pero la herramienta \\\"magic_function\\\" espera un parámetro de tipo \\\"string\\\", no un número entero como \\\"3\\\". Por favor, proporcione una entrada de tipo cadena de texto para poder aplicar la función mágica.\"\n",
      "  },\n",
      "  \"log\": \"Lo siento, pero la herramienta \\\"magic_function\\\" espera un parámetro de tipo \\\"string\\\", no un número entero como \\\"3\\\". Por favor, proporcione una entrada de tipo cadena de texto para poder aplicar la función mágica.\"\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:AgentExecutor\u001b[22m\u001b[39m] [1.12s] Exiting Chain run with output: {\n",
      "  \"input\": \"what is the value of magic_function(3)?\",\n",
      "  \"output\": \"Lo siento, pero la herramienta \\\"magic_function\\\" espera un parámetro de tipo \\\"string\\\", no un número entero como \\\"3\\\". Por favor, proporcione una entrada de tipo cadena de texto para poder aplicar la función mágica.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  input: \u001b[32m\"what is the value of magic_function(3)?\"\u001b[39m,\n",
       "  output: \u001b[32m'Lo siento, pero la herramienta \"magic_function\" espera un parámetro de tipo \"string\", no un número e'\u001b[39m... 112 more characters\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const badMagicTool = new DynamicStructuredTool({\n",
    "  name: \"magic_function\",\n",
    "  description: \"Applies a magic function to an input.\",\n",
    "  schema: z.object({\n",
    "    input: z.string(),\n",
    "  }),\n",
    "  func: async ({ input }) => {\n",
    "    return \"Sorry, there was an error. Please try again.\";\n",
    "  },\n",
    "});\n",
    "\n",
    "const badTools = [badMagicTool];\n",
    "\n",
    "const spanishAgentExecutorWithMaxIterations = new AgentExecutor({\n",
    "  agent: createToolCallingAgent({\n",
    "    llm: llm,\n",
    "    tools: badTools,\n",
    "    prompt: spanishPrompt,\n",
    "  }),\n",
    "  tools: badTools,\n",
    "  verbose: true,\n",
    "  maxIterations: 2,\n",
    "});\n",
    "\n",
    "await spanishAgentExecutorWithMaxIterations.invoke({ input: query });\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f5e7d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursion limit reached.\n"
     ]
    }
   ],
   "source": [
    "import { GraphRecursionError } from \"@langchain/langgraph\";\n",
    "\n",
    "const RECURSION_LIMIT = 2 * 2 + 1;\n",
    "\n",
    "const appWithBadTools = createReactAgent({ llm, tools: badTools });\n",
    "\n",
    "try {\n",
    "  await appWithBadTools.invoke({ messages: [new HumanMessage(query)] }, {\n",
    "    recursionLimit: RECURSION_LIMIT,\n",
    "  });\n",
    "} catch (e) {\n",
    "  if (e instanceof GraphRecursionError) {\n",
    "    console.log(\"Recursion limit reached.\");\n",
    "  } else {\n",
    "    throw e;\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5bf788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
