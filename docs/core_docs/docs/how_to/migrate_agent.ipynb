{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aef3e2be",
   "metadata": {},
   "source": [
    "# How to migrate from legacy LangChain agents to LangGraph\n",
    "\n",
    "Here we focus on how to move from legacy LangChain agents to LangGraph agents.\n",
    "LangChain agents (the\n",
    "[AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor)\n",
    "in particular) have multiple configuration parameters. In this notebook we will\n",
    "show how those parameters map to the LangGraph\n",
    "[react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent).\n",
    "\n",
    "#### Prerequisites\n",
    "\n",
    "This how-to guide uses Claude (model: \"claude-3-haiku-20240307\") as the LLM. Set\n",
    "your Anthropic API key to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef5404c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Deno.env.set(\"ANTHROPIC_API_KEY\", \"sk-...\");\n",
    "\n",
    "// Optional, add tracing in LangSmith\n",
    "// Deno.env.set(\"LANGCHAIN_API_KEY\", \"ls...\");\n",
    "Deno.env.set(\"LANGCHAIN_CALLBACKS_BACKGROUND\", \"true\");\n",
    "Deno.env.set(\"LANGCHAIN_TRACING_V2\", \"true\");\n",
    "Deno.env.set(\"LANGCHAIN_PROJECT\", \"How to migrate: LangGraphJS\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a5531b",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "For basic creation and usage of a tool-calling ReAct-style agent, the\n",
    "functionality is the same. First, let's define a model and tool(s), then we'll\n",
    "use those to create an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4dc1309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { DynamicStructuredTool } from \"@langchain/core/tools\";\n",
    "import { z } from \"zod\";\n",
    "import { ChatAnthropic } from \"@langchain/anthropic\";\n",
    "\n",
    "const llm = new ChatAnthropic({ model: \"claude-3-haiku-20240307\" });\n",
    "\n",
    "const magicTool = new DynamicStructuredTool({\n",
    "  name: \"magic_function\",\n",
    "  description: \"Applies a magic function to an input.\",\n",
    "  schema: z.object({\n",
    "    input: z.number(),\n",
    "  }),\n",
    "  func: async ({ input }: { input: number }) => {\n",
    "    return `${input + 2}`;\n",
    "  },\n",
    "});\n",
    "\n",
    "const tools = [magicTool];\n",
    "\n",
    "const query = \"what is the value of magic_function(3)?\";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901e7836",
   "metadata": {},
   "source": [
    "For the LangChain\n",
    "[AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor),\n",
    "we define a prompt with a placeholder for the agent's scratchpad. The agent can\n",
    "be invoked as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c04ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  input: \u001b[32m\"what is the value of magic_function(3)?\"\u001b[39m,\n",
       "  output: \u001b[32m\"The value of `magic_function(3)` is 5.\"\u001b[39m\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import {\n",
    "  ChatPromptTemplate,\n",
    "  MessagesPlaceholder,\n",
    "} from \"@langchain/core/prompts\";\n",
    "import { createToolCallingAgent } from \"langchain/agents\";\n",
    "import { AgentExecutor } from \"langchain/agents\";\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", \"You are a helpful assistant\"],\n",
    "  [\"human\", `{input}`],\n",
    "  new MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "]);\n",
    "\n",
    "const agent = createToolCallingAgent({ llm, tools, prompt });\n",
    "const agentExecutor = new AgentExecutor({ agent, tools });\n",
    "\n",
    "await agentExecutor.invoke({ input: query });\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295f87d2",
   "metadata": {},
   "source": [
    "LangGraph's\n",
    "[react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent)\n",
    "manages a state that is defined by a list of messages. It will continue to\n",
    "process the list until there are no tool calls in the agent's output. To kick it\n",
    "off, we input a list of messages. The output will contain the entire state of\n",
    "the graph-- in this case, the conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ceb1e4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "createReactAgent is not a function",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "TypeError: createReactAgent is not a function",
      "    at <anonymous>:2:13"
     ]
    }
   ],
   "source": [
    "import { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n",
    "\n",
    "const app = createReactAgent(llm, tools);\n",
    "\n",
    "let messages = app.invoke({ messages: [new HumanMessage(query)] });\n",
    "\n",
    "// {  \n",
    "//     input: query,\n",
    "//     output: messages.messages[messages.messages.length - 1].content,\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e1a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "const messageHistory = messages.messages;\n",
    "const newQuery = \"Pardon?\";\n",
    "\n",
    "messages = app.invoke({ messages: [...messageHistory, new HumanMessage(newQuery)] });\n",
    "\n",
    "{\n",
    "    input: newQuery,\n",
    "    output: messages.messages[messages.messages.length - 1].content,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14703a37",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "\n",
    "With legacy LangChain agents you have to pass in a prompt template. You can use\n",
    "this to control the agent.\n",
    "\n",
    "With LangGraph\n",
    "[react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent),\n",
    "by default there is no prompt. You can achieve similar control over the agent in\n",
    "a few ways:\n",
    "\n",
    "1. Pass in a system message as input\n",
    "2. Initialize the agent with a system message\n",
    "3. Initialize the agent with a function to transform messages before passing to\n",
    "   the model.\n",
    "\n",
    "Let's take a look at all of these below. We will pass in custom instructions to\n",
    "get the agent to respond in Spanish.\n",
    "\n",
    "First up, using AgentExecutor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8415a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "const spanishPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", \"You are a helpful assistant. Respond only in Spanish.\"],\n",
    "  [\"human\", `{input}`],\n",
    "  new MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "]);\n",
    "\n",
    "const spanishAgent = createToolCallingAgent(model, tools, spanishPrompt);\n",
    "const spanishAgentExecutor = new AgentExecutor({ agent: spanishAgent, tools });\n",
    "\n",
    "spanishAgentExecutor.invoke({ input: query });\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a17fc",
   "metadata": {},
   "source": [
    "Now, let's pass a custom system message to\n",
    "[react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent).\n",
    "This can either be a string or a LangChain SystemMessage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef588564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { SystemMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const systemMessage = \"You are a helpful assistant. Respond only in Spanish.\";\n",
    "\n",
    "// This could also be a SystemMessage object\n",
    "// const systemMessage = new SystemMessage(\"You are a helpful assistant. Respond only in Spanish.\");\n",
    "\n",
    "const appWithSystemMessage = createReactAgent(llm, tools, {\n",
    "  messagesModifier: systemMessage,\n",
    "});\n",
    "\n",
    "messages = appWithSystemMessage.invoke({ messages: [new HumanMessage(query)] });\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75668e20",
   "metadata": {},
   "source": [
    "We can also pass in an arbitrary function. This function should take in a list\n",
    "of messages and output a list of messages. We can do all types of arbitrary\n",
    "formatting of messages here. In this cases, let's just add a SystemMessage to\n",
    "the start of the list of messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc84ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "const modifyMessages = (messages: BaseMessage[]) => {\n",
    "  const systemPrompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", \"You are a helpful assistant. Respond only in Spanish.\"],\n",
    "    new MessagesPlaceholder(\"messages\"),\n",
    "  ]);\n",
    "\n",
    "  const modifiedMessages = systemPrompt.invoke({ messages }).toMessages();\n",
    "  modifiedMessages.push(\n",
    "    new HumanMessage(\"Also say 'Pandamonium!' after the answer.\"),\n",
    "  );\n",
    "  return modifiedMessages;\n",
    "};\n",
    "\n",
    "const appWithMessagesModifier = createReactAgent(llm, tools, {\n",
    "  messagesModifier: modifyMessages,\n",
    "});\n",
    "\n",
    "messages = appWithMessagesModifier.invoke({\n",
    "  messages: [new HumanMessage(query)],\n",
    "});\n",
    "\n",
    "console.log({\n",
    "  input: query,\n",
    "  output: messages.messages[messages.messages.length - 1].content,\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b88d65",
   "metadata": {},
   "source": [
    "## Memory\n",
    "\n",
    "With LangChain's\n",
    "[AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter),\n",
    "you could add chat\n",
    "[Memory](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.memory)\n",
    "so it can engage in a multi-turn conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc762f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatMessageHistory } from \"@langchain/core/memory\";\n",
    "import { RunnableWithMessageHistory } from \"@langchain/core/runnables\";\n",
    "\n",
    "const memory = new ChatMessageHistory({ sessionId: \"test-session\" });\n",
    "const agentExecutorWithMemory = new RunnableWithMessageHistory({\n",
    "  runnable: agentExecutor,\n",
    "  memoryFactory: () => memory,\n",
    "  inputMessagesKey: \"input\",\n",
    "  historyMessagesKey: \"chat_history\",\n",
    "});\n",
    "\n",
    "const config = { configurable: { session_id: \"test-session\" } };\n",
    "\n",
    "console.log(\n",
    "  agentExecutorWithMemory.invoke(\n",
    "    { input: \"Hi, I'm polly! What's the output of magic_function of 3?\" },\n",
    "    config,\n",
    "  ).output,\n",
    ");\n",
    "console.log(\"---\");\n",
    "console.log(\n",
    "  agentExecutorWithMemory.invoke({ input: \"Remember my name?\" }, config).output,\n",
    ");\n",
    "console.log(\"---\");\n",
    "console.log(\n",
    "  agentExecutorWithMemory.invoke(\n",
    "    { input: \"what was that output again?\" },\n",
    "    config,\n",
    "  ).output,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435254c4",
   "metadata": {},
   "source": [
    "#### In LangGraph\n",
    "\n",
    "Memory is just\n",
    "[persistence](https://langchain-ai.github.io/langgraph/how-tos/persistence/),\n",
    "aka\n",
    "[checkpointing](https://langchain-ai.github.io/langgraph/reference/checkpoints/).\n",
    "\n",
    "Add a `checkpointer` to the agent and you get chat memory for free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2cb398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { MemorySaver } from \"@langchain/langgraph/memory\";\n",
    "\n",
    "const memory = new MemorySaver();\n",
    "const appWithMemory = createReactAgent(model, tools, {\n",
    "  messagesModifier: systemMessage,\n",
    "  checkpointer: memory,\n",
    "});\n",
    "\n",
    "const config = { configurable: { thread_id: \"test-thread\" } };\n",
    "\n",
    "console.log(\n",
    "  appWithMemory.invoke(\n",
    "    {\n",
    "      messages: [\n",
    "        new HumanMessage(\n",
    "          \"Hi, I'm polly! What's the output of magic_function of 3?\",\n",
    "        ),\n",
    "      ],\n",
    "    },\n",
    "    config,\n",
    "  ).messages[0].content,\n",
    ");\n",
    "console.log(\"---\");\n",
    "console.log(\n",
    "  appWithMemory.invoke(\n",
    "    { messages: [new HumanMessage(\"Remember my name?\")] },\n",
    "    config,\n",
    "  ).messages[0].content,\n",
    ");\n",
    "console.log(\"---\");\n",
    "console.log(\n",
    "  appWithMemory.invoke(\n",
    "    { messages: [new HumanMessage(\"what was that output again?\")] },\n",
    "    config,\n",
    "  ).messages[0].content,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cbdc73",
   "metadata": {},
   "source": [
    "## Iterating through steps\n",
    "\n",
    "With LangChain's\n",
    "[AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter),\n",
    "you could iterate over the steps using the\n",
    "[stream](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream)\n",
    "(or async `astream`) methods or the\n",
    "[iter](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter)\n",
    "method. LangGraph supports stepwise iteration using\n",
    "[stream](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69049989",
   "metadata": {},
   "outputs": [],
   "source": [
    "for await (const step of agentExecutor.stream({ input: query })) {\n",
    "  console.log(step);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4122e30a",
   "metadata": {},
   "source": [
    "#### In LangGraph\n",
    "\n",
    "In LangGraph, things are handled natively using\n",
    "[stream](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.graph.CompiledGraph.stream)\n",
    "or the asynchronous `astream` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1245fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for await (\n",
    "  const step of app.stream(\n",
    "    { messages: [new HumanMessage(query)] },\n",
    "    { streamMode: \"updates\" },\n",
    "  )\n",
    ") {\n",
    "  console.log(step);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc77c685",
   "metadata": {},
   "source": [
    "## `return_intermediate_steps`\n",
    "\n",
    "Setting this parameter on AgentExecutor allows users to access\n",
    "intermediate_steps, which pairs agent actions (e.g., tool invocations) with\n",
    "their outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d28f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "const agentExecutorWithIntermediateSteps = new AgentExecutor({\n",
    "  agent,\n",
    "  tools,\n",
    "  returnIntermediateSteps: true,\n",
    "});\n",
    "\n",
    "const result = agentExecutorWithIntermediateSteps.invoke({ input: query });\n",
    "\n",
    "console.log(result.intermediateSteps);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c920179",
   "metadata": {},
   "source": [
    "By default the\n",
    "[react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent)\n",
    "in LangGraph appends all messages to the central state. Therefore, it is easy to\n",
    "see any intermediate steps by just looking at the full state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571aaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = app.invoke({ messages: [new HumanMessage(query)] });\n",
    "\n",
    "console.log(messages);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbccace",
   "metadata": {},
   "source": [
    "## `max_iterations`\n",
    "\n",
    "`AgentExecutor` implements a `max_iterations` parameter, whereas this is\n",
    "controlled via `recursion_limit` in LangGraph.\n",
    "\n",
    "Note that in AgentExecutor, an \"iteration\" includes a full turn of tool\n",
    "invocation and execution. In LangGraph, each step contributes to the recursion\n",
    "limit, so we will need to multiply by two (and add one) to get equivalent\n",
    "results.\n",
    "\n",
    "If the recursion limit is reached, LangGraph raises a specific exception type,\n",
    "that we can catch and manage similarly to AgentExecutor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf634aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "const badMagicTool = new DynamicStructuredTool({\n",
    "  name: \"magic_function\",\n",
    "  description: \"Applies a magic function to an input.\",\n",
    "  schema: z.object({\n",
    "    input: z.string(),\n",
    "  }),\n",
    "  func: async ({ input }) => {\n",
    "    return \"Sorry, there was an error. Please try again.\";\n",
    "  },\n",
    "});\n",
    "\n",
    "const badTools = [badMagicTool];\n",
    "\n",
    "const spanishAgentExecutorWithMaxIterations = new AgentExecutor({\n",
    "  agent: createToolCallingAgent(llm, badTools, spanishPrompt),\n",
    "  tools: badTools,\n",
    "  verbose: true,\n",
    "  maxIterations: 3,\n",
    "});\n",
    "\n",
    "spanishAgentExecutorWithMaxIterations.invoke({ input: query });\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b60fce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { GraphRecursionError } from \"@langchain/langgraph/errors\";\n",
    "\n",
    "const RECURSION_LIMIT = 2 * 3 + 1;\n",
    "\n",
    "const appWithBadTools = createReactAgent(llm, badTools);\n",
    "\n",
    "try {\n",
    "  for await (\n",
    "    const chunk of appWithBadTools.stream(\n",
    "      { messages: [new HumanMessage(query)] },\n",
    "      { recursionLimit: RECURSION_LIMIT },\n",
    "      { streamMode: \"values\" },\n",
    "    )\n",
    "  ) {\n",
    "    console.log(chunk.messages[chunk.messages.length - 1]);\n",
    "  }\n",
    "} catch (error) {\n",
    "  if (error instanceof GraphRecursionError) {\n",
    "    console.log({\n",
    "      input: query,\n",
    "      output: \"Agent stopped due to max iterations.\",\n",
    "    });\n",
    "  } else {\n",
    "    throw error;\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c193398",
   "metadata": {},
   "source": [
    "## `max_execution_time`\n",
    "\n",
    "`AgentExecutor` implements a `max_execution_time` parameter, allowing users to\n",
    "abort a run that exceeds a total time limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883b8ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "const slowMagic = new DynamicStructuredTool({\n",
    "  name: \"magic_function\",\n",
    "  description: \"Applies a magic function to an input.\",\n",
    "  schema: z.object({\n",
    "    input: z.string(),\n",
    "  }),\n",
    "  func: async ({ input }) => {\n",
    "    await new Promise((resolve) => setTimeout(resolve, 2500));\n",
    "    return \"Sorry, there was an error. Please try again.\";\n",
    "  },\n",
    "});\n",
    "\n",
    "const slowTools = [slowMagic];\n",
    "\n",
    "const slowAgentExecutor = new AgentExecutor({\n",
    "  agent: createToolCallingAgent(model, slowTools),\n",
    "  tools: slowTools,\n",
    "  maxExecutionTime: 2000,\n",
    "  verbose: true,\n",
    "});\n",
    "\n",
    "slowAgentExecutor.invoke({ input: query });\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024d2150",
   "metadata": {},
   "source": [
    "With LangGraph's react agent, you can control timeouts on two levels.\n",
    "\n",
    "You can set a `stepTimeout` to bound each **step**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3858edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "const appWithSlowTools = createReactAgent(llm, slowTools);\n",
    "appWithSlowTools.stepTimeout = 2000;\n",
    "\n",
    "try {\n",
    "  for await (\n",
    "    const chunk of appWithSlowTools.stream({\n",
    "      messages: [new HumanMessage(query)],\n",
    "    })\n",
    "  ) {\n",
    "    console.log(chunk);\n",
    "    console.log(\"------\");\n",
    "  }\n",
    "} catch (error) {\n",
    "  if (error instanceof TimeoutError) {\n",
    "    console.log({\n",
    "      input: query,\n",
    "      output: \"Agent stopped due to max iterations.\",\n",
    "    });\n",
    "  } else {\n",
    "    throw error;\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f707ace8",
   "metadata": {},
   "source": [
    "The other way to set a single max timeout for an entire run is to directly use\n",
    "the deno stdlib\n",
    "[Promise.any()](https://doc.deno.land/deno/stable/~/Deno.Promise.any) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e32615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try {\n",
    "  await Promise.any([\n",
    "    appWithSlowTools.astream({ messages: [new HumanMessage(query)] }).collect(),\n",
    "    new Promise((_, reject) =>\n",
    "      setTimeout(() => reject(new TimeoutError()), 3000)\n",
    "    ),\n",
    "  ]);\n",
    "} catch (error) {\n",
    "  if (error instanceof TimeoutError) {\n",
    "    console.log(\"Task Cancelled.\");\n",
    "  } else {\n",
    "    throw error;\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf61b042",
   "metadata": {},
   "source": [
    "## `early_stopping_method`\n",
    "\n",
    "With LangChain's\n",
    "[AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter),\n",
    "you could configure an\n",
    "[early_stopping_method](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.early_stopping_method)\n",
    "to either return a string saying \"Agent stopped due to iteration limit or time\n",
    "limit.\" (`\"force\"`) or prompt the LLM a final time to respond (`\"generate\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d6bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "const earlyStoppingAgentExecutor = new AgentExecutor({\n",
    "  agent: createToolCallingAgent(model, badTools, prompt),\n",
    "  tools: badTools,\n",
    "  earlyStoppingMethod: \"force\",\n",
    "  maxIterations: 1,\n",
    "});\n",
    "\n",
    "const earlyStoppingResult = earlyStoppingAgentExecutor.invoke({ input: query });\n",
    "console.log(\"Output with earlyStoppingMethod='force':\");\n",
    "console.log(earlyStoppingResult.output);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d29fcd7",
   "metadata": {},
   "source": [
    "#### In LangGraph\n",
    "\n",
    "In LangGraph, you can explicitly handle the response behavior outside the agent,\n",
    "since the full state can be accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0cb9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "const RECURSION_LIMIT_SHORT = 2 * 1 + 1;\n",
    "\n",
    "try {\n",
    "  for await (\n",
    "    const chunk of appWithBadTools.stream(\n",
    "      { messages: [new HumanMessage(query)] },\n",
    "      { recursionLimit: RECURSION_LIMIT_SHORT },\n",
    "      { streamMode: \"values\" },\n",
    "    )\n",
    "  ) {\n",
    "    console.log(chunk.messages[chunk.messages.length - 1]);\n",
    "  }\n",
    "} catch (error) {\n",
    "  if (error instanceof GraphRecursionError) {\n",
    "    console.log({\n",
    "      input: query,\n",
    "      output: \"Agent stopped due to max iterations.\",\n",
    "    });\n",
    "  } else {\n",
    "    throw error;\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f69afe",
   "metadata": {},
   "source": [
    "## `trim_intermediate_steps`\n",
    "\n",
    "With LangChain's\n",
    "[AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor),\n",
    "you could trim the intermediate steps of long-running agents using\n",
    "[trim_intermediate_steps](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.trim_intermediate_steps),\n",
    "which is either an integer (indicating the agent should keep the last N steps)\n",
    "or a custom function.\n",
    "\n",
    "For instance, we could trim the value so the agent only sees the most recent\n",
    "intermediate step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc91d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "let magicStepNum = 1;\n",
    "\n",
    "const countingMagicTool = new DynamicStructuredTool({\n",
    "  name: \"magic_function\",\n",
    "  description: \"Applies a magic function to an input.\",\n",
    "  schema: z.object({\n",
    "    input: z.number(),\n",
    "  }),\n",
    "  func: async ({ input }) => {\n",
    "    console.log(`Call number: ${magicStepNum}`);\n",
    "    magicStepNum += 1;\n",
    "    return input + magicStepNum;\n",
    "  },\n",
    "});\n",
    "\n",
    "const countingTools = [countingMagicTool];\n",
    "\n",
    "const trimSteps = (steps) => {\n",
    "  // Let's give the agent amnesia\n",
    "  return [];\n",
    "};\n",
    "\n",
    "const agentExecutorWithTrim = new AgentExecutor({\n",
    "  agent: createToolCallingAgent(llm, countingTools, prompt),\n",
    "  tools: countingTools,\n",
    "  trimIntermediateSteps: trimSteps,\n",
    "});\n",
    "\n",
    "const queryWithCounts =\n",
    "  \"Call the magic function 4 times in sequence with the value 3. You cannot call it multiple times at once.\";\n",
    "\n",
    "for await (\n",
    "  const step of agentExecutorWithTrim.stream({\n",
    "    input: queryWithCounts,\n",
    "  })\n",
    ") {\n",
    "  // no-op\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757b653f",
   "metadata": {},
   "source": [
    "#### In LangGraph\n",
    "\n",
    "We can use the\n",
    "[`messagesModifier`](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent)\n",
    "just as before when passing in [prompt templates](#prompt-templates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82623e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "let magicStepNum2 = 1;\n",
    "\n",
    "const countingMagicTool2 = new DynamicStructuredTool({\n",
    "  name: \"magic_function\",\n",
    "  description: \"Applies a magic function to an input.\",\n",
    "  schema: z.object({\n",
    "    input: z.number(),\n",
    "  }),\n",
    "  func: async ({ input }) => {\n",
    "    console.log(`Call number: ${magicStepNum2}`);\n",
    "    magicStepNum2 += 1;\n",
    "    return input + magicStepNum2;\n",
    "  },\n",
    "});\n",
    "\n",
    "const countingTools2 = [countingMagicTool2];\n",
    "\n",
    "const amnesiaMessagesModifier = (messages: BaseMessage[]) => {\n",
    "  // Give the agent amnesia, only keeping the original user query\n",
    "  return [new SystemMessage(\"You are a helpful assistant\"), messages[0]];\n",
    "};\n",
    "\n",
    "const amnesiaApp = createReactAgent(model, countingTools2, {\n",
    "  messagesModifier: amnesiaMessagesModifier,\n",
    "});\n",
    "\n",
    "try {\n",
    "  for await (\n",
    "    const step of amnesiaApp.stream(\n",
    "      { messages: [new HumanMessage(queryWithCounts)] },\n",
    "      { streamMode: \"updates\" },\n",
    "    )\n",
    "  ) {\n",
    "    // no-op\n",
    "  }\n",
    "} catch (error) {\n",
    "  if (error instanceof GraphRecursionError) {\n",
    "    console.log(\"Stopping agent prematurely due to triggering stop condition\");\n",
    "  } else {\n",
    "    throw error;\n",
    "  }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.16.1"
   }
  },
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
