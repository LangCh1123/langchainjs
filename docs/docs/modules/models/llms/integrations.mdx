---
sidebar_position: 2
sidebar_label: Integrations
---

# Integrations: LLMs

LangChain offers a number of LLM implementations that integrate with various model providers. These are:

## `OpenAI`

```typescript
import { OpenAI } from "langchain/llms";

const model = new OpenAI({ temperature: 0.9 });
const res = await model.call(
  "What would be a good company name a company that makes colorful socks?"
);
console.log({ res });
```

## `HuggingFaceInference`

```typescript
import { HuggingFaceInference } from "langchain/llms";

const model = new HuggingFaceInference();
const res = await model.call("1 + 1 =");
console.log({ res });
```

## `Cohere`

```typescript
import { Cohere } from "langchain/llms";

const model = new Cohere({ maxTokens: 20 });
const res = await model.call(
  "What would be a good company name a company that makes colorful socks?"
);
console.log({ res });
```

## Additional LLM Implementations

### `PromptLayerOpenAI`

LangChain integrates with PromptLayer for logging and debugging prompts and responses. To add support for PromptLayer:

1. Create a PromptLayer account here: [https://promptlayer.com](https://promptlayer.com).
2. Create an API token and pass it either as `promptLayerApiKey` argument in the `PromptLayerOpenAI` constructor or in the `PROMPT_LAYER_API_KEY` environment variable.

```typescript
const model = new PromptLayerOpenAI({ temperature: 0.9 });
const res = await model.call(
  "What would be a good company name a company that makes colorful socks?"
);
```

The request and the response will be logged in the [PromptLayer dashboard](https://promptlayer.com/home).

> **_Note:_** In streaming mode PromptLayer will not log the response.
