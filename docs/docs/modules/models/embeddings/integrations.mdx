---
sidebar_position: 3
sidebar_label: Integrations
---

import CodeBlock from "@theme/CodeBlock";

# Integrations: Embeddings

LangChain offers a number of Embeddings implementations that integrate with various model providers. These are:

## `OpenAIEmbeddings`

The `OpenAIEmbeddings` class uses the OpenAI API to generate embeddings for a given text. By default it strips new line characters from the text, as recommended by OpenAI, but you can disable this by passing `stripNewLines: false` to the constructor.

```typescript
import { OpenAIEmbeddings } from "langchain/embeddings/openai";

const embeddings = new OpenAIEmbeddings({
  openAIApiKey: "YOUR-API-KEY", // In Node.js defaults to process.env.OPENAI_API_KEY
});
```

## Azure `OpenAIEmbeddings`

The `OpenAIEmbeddings` class uses the OpenAI API on Azure to generate embeddings for a given text. By default it strips new line characters from the text, as recommended by OpenAI, but you can disable this by passing `stripNewLines: false` to the constructor.

```typescript
import { OpenAIEmbeddings } from "langchain/embeddings/openai";

const embeddings = new OpenAIEmbeddings({
  azureOpenAIApiKey: "YOUR-API-KEY", // In Node.js defaults to process.env.AZURE_OPENAI_API_KEY
  azureOpenAIApiInstanceName: "YOUR-INSTANCE-NAME", // In Node.js defaults to process.env.AZURE_OPENAI_API_INSTANCE_NAME
  azureOpenAIApiDeploymentName: "YOUR-DEPLOYMENT-NAME", // In Node.js defaults to process.env.AZURE_OPENAI_API_DEPLOYMENT_NAME
  azureOpenAIApiVersion: "YOUR-API-VERSION", // In Node.js defaults to process.env.AZURE_OPENAI_API_VERSION
  azureOpenAIBasePath: "YOUR-AZURE-OPENAI-BASE-PATH", // In Node.js defaults to process.env.AZURE_OPENAI_BASE_PATH
});
```

## `GooglePaLMEmbeddings`

The [Google PaLM API](https://developers.generativeai.google/products/palm) can be integrated by first
installing the required packages:

```bash npm2yarn
npm install google-auth-library @google-ai/generativelanguage
```

Create an **API key** from [Google MakerSuite](https://makersuite.google.com/app/apikey). You can then set
the key as `GOOGLE_PALM_API_KEY` environment variable or pass it as `apiKey` parameter while instantiating
the model.

import GooglePaLMExample from "@examples/models/embeddings/googlepalm.ts";

<CodeBlock language="typescript">{GooglePaLMExample}</CodeBlock>

## `Google Vertex AI`

There are two embedding classes available through Google Clouds's Vertex AI platform:

- The `GoogleVertexAIEmbeddings` class uses the PaLM models to generate embeddings
  for a given text.
- The `GoogleVertexAIImageEmbeddings` class uses a different model that can
  create embeddings for both text and images where the embeddings occupy the
  same vector space. So you can compare images to images or compare text to
  images.

The Vertex AI implementation is meant to be used in Node.js and not
directly in a browser, since it requires a service account to use.

Before running this code, you should make sure the Vertex AI API is
enabled for the relevant project in your Google Cloud dashboard and that you've authenticated to
Google Cloud using one of these methods:

- You are logged into an account (using `gcloud auth application-default login`)
  permitted to that project.
- You are running on a machine using a service account that is permitted
  to the project.
- You have downloaded the credentials for a service account that is permitted
  to the project and set the `GOOGLE_APPLICATION_CREDENTIALS` environment
  variable to the path of this file.

```bash npm2yarn
npm install google-auth-library
```

import GoogleVertexAIExample from "@examples/models/embeddings/googlevertexai.ts";

<CodeBlock language="typescript">{GoogleVertexAIExample}</CodeBlock>

The `GoogleVertexAIImageEmbeddings` class provides additional methods that are
parallels to the `embedDocuments()` and `embedQuery()` methods:

- `embedImage()` and `embedImageQuery()` take node `Buffer` objects that are expected to
  contain an image.
- `embedMedia()` and `embedMediaQuery()` take an object that contain a `text` string
  field, an `image` Buffer field, or both and returns a similarly constructed object
  containing the respective vectors.

import GoogleVertexAIImageExample from "@examples/models/embeddings/googlevertexai_image.ts";

<CodeBlock language="typescript">{GoogleVertexAIImageExample}</CodeBlock>

**Note:** The Google Vertex AI embeddings models have different vector sizes
than OpenAI's standard model, so some vector stores may not handle them correctly.

- The `textembedding-gecko` model in `GoogleVertexAIEmbeddings` provides 768 dimensions.
- The `multimodalembedding@001` model in `GoogleVertexAIImageEmbeddings` provides 1408 dimensions.

## `CohereEmbeddings`

The `CohereEmbeddings` class uses the Cohere API to generate embeddings for a given text.

```bash npm2yarn
npm install cohere-ai
```

```typescript
import { CohereEmbeddings } from "langchain/embeddings/cohere";

const embeddings = new CohereEmbeddings({
  apiKey: "YOUR-API-KEY", // In Node.js defaults to process.env.COHERE_API_KEY
});
```

## `TensorFlowEmbeddings`

This Embeddings integration runs the embeddings entirely in your browser or Node.js environment, using [TensorFlow.js](https://www.tensorflow.org/js). This means that your data isn't sent to any third party, and you don't need to sign up for any API keys. However, it does require more memory and processing power than the other integrations.

```bash npm2yarn
npm install @tensorflow/tfjs-core @tensorflow/tfjs-converter @tensorflow-models/universal-sentence-encoder @tensorflow/tfjs-backend-cpu
```

```typescript
import "@tensorflow/tfjs-backend-cpu";
import { TensorFlowEmbeddings } from "langchain/embeddings/tensorflow";

const embeddings = new TensorFlowEmbeddings();
```

This example uses the CPU backend, which works in any JS environment. However, you can use any of the backends supported by TensorFlow.js, including GPU and WebAssembly, which will be a lot faster. For Node.js you can use the `@tensorflow/tfjs-node` package, and for the browser you can use the `@tensorflow/tfjs-backend-webgl` package. See the [TensorFlow.js documentation](https://www.tensorflow.org/js/guide/platform_environment) for more information.

## `HuggingFaceInferenceEmbeddings`

This Embeddings integration uses the HuggingFace Inference API to generate embeddings for a given text using by default the `sentence-transformers/distilbert-base-nli-mean-tokens` model. You can pass a different model name to the constructor to use a different model.

```bash npm2yarn
npm install @huggingface/inference@1
```

```typescript
import { HuggingFaceInferenceEmbeddings } from "langchain/embeddings/hf";

const embeddings = new HuggingFaceInferenceEmbeddings({
  apiKey: "YOUR-API-KEY", // In Node.js defaults to process.env.HUGGINGFACEHUB_API_KEY
});
```
