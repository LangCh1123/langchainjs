# OpenAI Assistant

:::info
The [OpenAI Assistant API](https://platform.openai.com/docs/assistants/overview) is still in beta. OpenAI does not recommend it for production use.
:::

OpenAI released a new API for a conversational agent like system called Assistant.
It's similar to LangChain's AgentExecutor, but includes some other features like a stateful API, integrated tools ([code interpreter](https://platform.openai.com/docs/assistants/tools/code-interpreter), [retrieval])(https://platform.openai.com/docs/assistants/tools/knowledge-retrieval) and the ability to pass custom tools (similar to [OpenAI functions](https://js.langchain.com/docs/modules/agents/agent_types/openai_functions_agent)).

We've implemented the assistant API in LangChain with some helpful abstractions. In this guide we'll go over those, and show how to use them to create powerful assistants.

## Creating an assistant

Creating an assistant is easy. Use the `create` method and pass in a model ID, and optionally more parameters to further customize your assistant.

```typescript
import { OpenAIAssistantRunnable } from "experimental/openai_assistant";
```

```typescript
const assistant = await OpenAIAssistantRunnable.create({
  model: "gpt-4-1106-preview",
});
const assistantResponse = await assistant.invoke({
  content: "Hello world!",
});
console.log(assistantResponse);
/**
    [
      {
        id: 'msg_OBH60nkVI40V9zY2PlxMzbEI',
        thread_id: 'thread_wKpj4cu1XaYEVeJlx4yFbWx5',
        role: 'assistant',
        content: [ 
          {
            type: 'text',
            value: 'Hello there! What can I do for you?'
          }
        ],
        assistant_id: 'asst_RtW03Vs6laTwqSSMCQpVND7i',
        run_id: 'run_4Ve5Y9fyKMcSxHbaNHOFvdC6',
      }
    ]
   */
```

In the example above we're calling our assistant via the `.invoke` method because the OpenAI assistant is a [Runnable](/docs/expression_language/).
Having the `OpenAIAssistantRunnable` be apart of the Expression Language allows for seamless integrations with other LangChain features like the `AgentExecutor`.

In this next example we'll show how you can turn your assistant into an agent.

## Assistant as an agent

```typescript
import { AgentExecutor } from "langchain/agents";
import { Tool } from "langchain/tools";
import { OpenAIAssistantRunnable } from "experimental/openai_assistant";
```

The first step is to define a list of tools you want to pass to your assistant.
Here we'll only define one for simplicity's sake, however the assistant API allows for passing in a list of tools, and from there the model can use multiple tools at once.

:::note
Only models released >= 1106 are able to use multiple tools at once.
:::

```typescript
function getCurrentWeather(location: string, _unit = "fahrenheit") {
  if (location.toLowerCase().includes("tokyo")) {
    return JSON.stringify({ location, temperature: "10", unit: "celsius" });
  } else if (location.toLowerCase().includes("san francisco")) {
    return JSON.stringify({ location, temperature: "72", unit: "fahrenheit" });
  } else {
    return JSON.stringify({ location, temperature: "22", unit: "celsius" });
  }
}
class WeatherTool extends Tool {
  name = "get_current_weather";

  description = "Get the current weather in a given location";

  constructor() {
    super();
  }

  async _call(input: { location: string; unit: string }) {
    const { location, unit } = input;
    const result = getCurrentWeather(location, unit);
    return result;
  }
}
const tools = [
  {
    type: "function",
    function: {
      name: "get_current_weather",
      description: "Get the current weather in a given location",
      parameters: {
        type: "object",
        properties: {
          location: {
            type: "string",
            description: "The city and state, e.g. San Francisco, CA",
          },
          unit: { type: "string", enum: ["celsius", "fahrenheit"] },
        },
        required: ["location"],
      },
    },
  },
];
```

In the above code we've defined three things:

- A function for the agent to call if the model requests it.
- A tool class which we'll pass to the `AgentExecutor`
- The tool schema to pass through to the `OpenAIAssistantRunnable`

Next, we construct the `OpenAIAssistantRunnable` and pass it to the `AgentExecutor`.

```typescript
const agent = await OpenAIAssistantRunnable.create({
  model: "gpt-4-1106-preview",
  instructions:
    "You are a helpful assistant that provides weather information.",
  name: "Weather Assistant",
  tools,
  asAgent: true,
});
const agentExecutor = AgentExecutor.fromAgentAndTools({
  agent,
  tools: [new WeatherTool()],
});
```

Note how we're setting `asAgent` to `true`, this input parameter tells the `OpenAIAssistantRunnable` to return different, agent acceptable outputs for actions or finished conversations.

Above we're also doing something a little different from the first example by passing in input parameters for `instructions` and `name`.
These are optional parameters, with the instructions being passed as extra context to the model, and the name being used to identify the assistant in the OpenAI dashboard.

Finally to invoke our executor we call the `.invoke` method in the exact same way as we did in the first example.

```typescript
const assistantResponse = await agentExecutor.invoke({
  content: "What's the weather in Tokyo and San Francisco?",
});
console.log(assistantResponse);
```

Here we asked a question which contains two sub questions inside: `What's the weather in Tokyo?` and `What's the weather in San Francisco?`.
In order for the `OpenAIAssistantRunnable` to answer that it returned two sets of function call arguments for each question, demonstrating it's ability to call multiple functions at once.

## Assistant tools

OpenAI currently offers two tools for the assistant API: a [code interpreter](https://platform.openai.com/docs/assistants/tools/code-interpreter) and a [knowledge retrieval](https://platform.openai.com/docs/assistants/tools/knowledge-retrieval) tool.
You can offer these tools to the assistant simply by passing them in as part of the `tools` parameter when creating the assistant.

```typescript
const assistant = await OpenAIAssistantRunnable.create({
  model: "gpt-4-1106-preview",
  instructions:
    "You are a helpful assistant that provides answers to math problems.",
  name: "Math Assistant",
  tools: [{ type: "code_interpreter" }],
});
```

Since we're passing `code_interpreter` as a tool, the assistant will now be able to execute Python code, allowing for more complex tasks normal LLMs are not capable of doing well, like math.

```typescript
const assistantResponse = await assistant.invoke({
  content: "What's 10 - 4 raised to the 2.7",
});
console.log(assistantResponse);
/**
[
  {
    id: 'msg_OBH60nkVI40V9zY2PlxMzbEI',
    thread_id: 'thread_wKpj4cu1XaYEVeJlx4yFbWx5',
    role: 'assistant',
    content: [
      {
        type: 'text',
        text: {
          value: 'The result of 10 - 4 raised to the 2.7 is approximately -32.22.',
          annotations: []
        }
      }
    ],
    assistant_id: 'asst_RtW03Vs6laTwqSSMCQpVND7i',
    run_id: 'run_4Ve5Y9fyKMcSxHbaNHOFvdC6',
  }
]
*/
```

Here the assistant was able to utilize the `code_interpreter` tool to calculate the answer to our question.
