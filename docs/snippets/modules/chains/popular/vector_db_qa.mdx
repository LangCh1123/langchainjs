import RetrievalQARunnableExample from "@examples/chains/retrieval_qa.ts";
import RetrievalQARunnableExampleCustom from "@examples/chains/retrieval_qa_custom.ts";
import RetrievalQAExampleCustomPrompt from "@examples/chains/retrieval_qa_custom_prompt.ts";
import CodeBlock from "@theme/CodeBlock";

The following examples combing a `Retriever` (in this case a vector store) with a question answering chain to do question answering.

Legacy non Runnable docs can be found [here](https://js.langchain.com/docs/modules/chains/popular/vector_db_qa_legacy).

## Usage

In the below example, we are using a `VectorStore` as the `Retriever`, along with a `RunnableSequence` to do question answering.
We create a `ChatPromptTemplate` which contains our base system prompt and an input variable for the `question`.

<CodeBlock language="typescript">{RetrievalQARunnableExample}</CodeBlock>

## Custom `QA` chain

In the below example, we are using a `VectorStore` as the `Retriever` and implementing a similar flow to the `MapReduceDocumentsChain` chain.
In this example we're querying relevant documents based on the query, and from those documents we use an LLM to parse out only the relevant information.
Once all the relevant information is gathered we pass it once more to an LLM to generate the answer.

<CodeBlock language="typescript">{RetrievalQARunnableExampleCustom}</CodeBlock>

## Custom prompts

You can pass in custom prompts to do question answering. These prompts are the same prompts as you can pass into the base question answering chains.

<CodeBlock language="typescript">{RetrievalQAExampleCustomPrompt}</CodeBlock>
